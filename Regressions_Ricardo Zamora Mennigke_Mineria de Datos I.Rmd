---
title: "Tarea 8 y 9_Ricardo Zamora Mennigke_Mineria de Datos I"
author: "Ricardo Zamora Mennigke"
date: "5/27/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```

#Tarea 08 y 09
#Mineria de Datos I
#Ricardo Zamora Mennigke


```{r cars}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(glue)
library(scales)
library(xgboost)
library(randomForest)
```

Pregunta 1: Suponga que trabajamos para un banco y se nos pide predecir el monto promedio de deuda en tarjeta de cr´edito de una cartera de clientes relativamente nuevos, basado en otra cartera de comportamiento y estructura similar de la cual s´ı se tiene informaci´on de deuda en tarjeta de cr´edito. En este ejercicio hacemos uso de la tabla de datos DeudaCredito.csv que contiene informaci´on de los clientes en una de las principales carteras de cr´edito del banco, e incluye variables que describen cada cliente tanto dentro del banco como fuera de ´este. Esta tabla de datos contiene 400 clientes y 11 variables que los describen. Seguidamente se explican las variables que conforman la tabla.

```{r pruiwuifrgeghvvvvvvvvvvvvvvfjhdessureg, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase8")
datos<-read.csv("DeudaCredito.csv",dec='.',header=T)
str(datos)

```

```{r pruiwuifrjdhfjhdeegweyufguyfgssureg, echo=TRUE}
suppressMessages(suppressWarnings(library(FactoMineR)))
suppressMessages(suppressWarnings(library(car)))
Atipicos<-(Boxplot(~Balance, data=datos, id.method="y",col="Blue")) #Monto promedio de deuda en tarjeta de cr´edito del cliente, en d´olares
```

```{r pruiwuifrjdhfjegwgfyegfgfgfghdessureg, echo=TRUE}
Atipicos<-(Boxplot(~Ingreso, data=datos, id.method="y",col="Blue")) #Ingreso: Ingreso del cliente, en miles de d´olares.
```

```{r pruiwuifrjdhfgjdtdjtyjdtjtjhdessureg, echo=TRUE}
Atipicos<-(Boxplot(~CalifCredit, data=datos, id.method="y",col="Blue")) #Ingreso: Ingreso del cliente, en miles de d´olares.
```

```{r pueyfifihhhhhfhgikdfhgihjfjec, echo=TRUE}
# Elimino variables categóricas
datos2 <- datos[,-c(1,8,9,11)] ##verificar correlaciones con variables numericas
head(datos2)
```

```{r pueyfifihhhhhjfjeufhyiuyfeiufuc, echo=TRUE}
library(corrplot)
matriz.correlacion<-cor(datos2)
corrplot(matriz.correlacion)
```
Debe tenerse en cuenta que aqui se denota unicamente un punto de vista inicial al eliminar variables categoricas y respuesta para analizar si existe cierta correlacion entre variables, sirve como un punto de vista inicial, para ver si pueden existir ciertos problemas de estimacion. Se puede observar que las variables predictoras Ingreso, Limite y Calificacion, estan significativamente correlacionadas con la variable de respuesta, es decir, en otros casos podrian agruparse como una sola variable. Esto es un indicativo de que al estimar las variables puedan comprometer la estimacion por lo que se debe tomar al analizar la respuesta y el resultado final del modelo.


```{r pueyfifihtgfuierygaighhhhhjfjec, echo=TRUE}
muestra <- sample(1:nrow(datos),floor(nrow(datos)*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
nrow(ttesting)
nrow(taprendizaje)


```

2. Basado en las estad´ısticas b´asicas explique cu´al variable num´erica parece ser la mejor para predecir la deuda en tarjeta de cr´etido.

```{r pruiwuifrgeghfjhdpppppppppppppppessureg, echo=TRUE}
summary(datos)
```

La mejor variable numerica para predecir la deuda en la tarjeta de credito es justamente la variable balance, ya que indica el Monto promedio de deuda en tarjeta de cr´edito del cliente, en d´olares. Dependiendo del estudio podria tambien ser interesante analizar la generacion de la calificacion crediticia pero esta es una calificacion que no  


3. Genere un modelo de regresi´on lineal m´ultiple incluyendo las todas las variables predictoras. ¿Cu´ales coeficientes obtiene para los β? D´e una interpretaci´on de 3 de los coeficientes que se obtienen en el modelo. ¿Cu´al variable parece tener m´as impacto sobre la variable a predecir y por qu´e?

```{r pruiwuifrgdddddddddddddeghfjhdessureg, echo=TRUE}
modelo <- lm(Balance ~ ., data = datos)
modelo 
```


```{r pruiwuifrgeghfjhdelllllllllllssureg, echo=TRUE}
summary(modelo)
```

Usando todos los datos se pueden sacar conclusiones al modelo mostrado abajo con solo training. En este caso los valores de β son los estimadores (estimate) del modelo. Aqui debe tenerse en cuenta que el modelo sin reducir seria:
y = -496.62039 + 0.04105X - 7.80740 * Ingreso + ... + 9.29289 * EtnicidadCaucasico
Tomando como principal criterio las probabilidades existen varias variables que resultan significativas para la variable de respuesta especialmente el ingreso y si es Estdudiante. Es curioso ya que el t valor muestra un valor negativo igual que el estimador lo que indica que entre mayor ingreso menor problema crediticio. Contrario si es EstudianteSI esta variable tiene el mayor impacto, ya que si es estudiante su deuda aumenta segun el estimador 426.16715. Interpretando 3 coeficientes como ejemplo, por cada aumento en una unidad de Ingreso (en miles de dolares) la deuda en tarjeta de credito de la persona se reduce en 7,80740 dolares. Por cada tarjeta de credito adicional (Tarjetas) se estima que la persona tiene 17,83639 dolares mas un su monto de deuda en su tarjeta de credito. Finalmente por cada ano adicional en la edad del cliente se estima que su deuda es -0.62955 dolares mas baja.

```{r pruiwuifrgeggggggggggggggghfjhdessureg, echo=TRUE}
# Calcula el modelo usando solo los datos de training
modelo.lm <- lm(Balance~., data = taprendizaje)
modelo.lm
```

4. ¿Qu´e error se obtiene sobre la tabla de testing para el modelo de regresi´on lineal? Interprete las medidas de error obtenidas.


```{r pruiwuifrgeghfjhdjjjjjjjjjjjjjjjjjjjjjessureg, echo=TRUE}
# Residual Sum of Square (RSS)
RSS <- function(Pred,Real) {
  ss <- sum((Real-Pred)^2)
  return(ss)
}

# NumPred es el número total de predictores por eso se resta 1 (que es realidad sumar 1)
RSE<-function(Pred,Real,NumPred) {
  N<-length(Real)-NumPred-1  # <- length(Real)-(NumPred+1)
  ss<-sqrt((1/N)*RSS(Pred,Real))
  return(ss)
}

MSE <- function(Pred,Real) {
  N<-length(Real)
  ss<-(1/N)*RSS(Pred,Real)
  return(ss)
}

error.relativo <- function(Pred,Real) {
  ss<-sum(abs(Real-Pred))/sum(abs(Real))
  return(ss)
}

# Funciones para desplegar precisión
indices.precision <- function(real, prediccion,cantidad.variables.predictoras) {
  return(list(error.cuadratico = MSE(prediccion,real),
              raiz.error.cuadratico = RSE(prediccion,real,cantidad.variables.predictoras),
              error.relativo = error.relativo(prediccion,real),
              correlacion = as.numeric(cor(prediccion,real))))
}


# Gráfico de dispersión entre el valor real de la variable a predecir y la predicción del modelo.
plot.real.prediccion <- function(real, prediccion, modelo = "") {
  g <- ggplot(data = data.frame(Real = real, Prediccion = as.numeric(prediccion)), mapping = aes(x = Real, y = Prediccion)) +
    geom_point(size = 1, col = "dodgerblue3") +
    labs(title = paste0("Real vs Predicción", ifelse(modelo == "", "", paste(", con", modelo))),
         x = "Real",
         y = "Predicción")
  return(g)
}
```

```{r pruiwuifrgeghfjhdebbbbbbbbbbbbbssureg, echo=TRUE}
numero.predictoras <- dim(datos)[2] - 1
# Hace la Predicción
prediccion <- predict(modelo.lm, ttesting)
# Medición de precisión
pre.lm <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.lm
```

Medida de error en este caso se mide facilmente por la raiz del error cuadratico medio en terminos podria decirse para este caso mas "netos". Ya que lo que indica este coeficiente es que la estimacion del modelo tiene un error absoluto estimado de + (mas) o (-) 94.58605 dolares en la estimacion final del Balance de la deuda en tarjetas de credito. El error relativo indica que el error de estimacion es aproximado de 12,68% y ademas la correlacion entre el valor real y el valor predicho es 0.9842869, es decir entre mas cercano a 1 mejor. En terminos generales la estimacion pues no es ideal pero tiene una estimacion predicha bastante significativamente precisa. Viendo de hecho la grafica Real vs Prediccion se denota que el modelo se ajusta bien a la funcion identidad, dando en realidad problemas en las estimaciones de clientes con deudas bajas o nulas, relacionado al residual standard error en 98,8.

```{r pruiwuifrgeghfttttttttttttttttjhdessureg, echo=TRUE}
# Gráfico real vs predicción, con curva de mejor ajuste lineal
g <- plot.real.prediccion(ttesting$Balance, prediccion, modelo = "Regresión Lineal")
g + geom_smooth(method = lm, size = 0.4, color = "red", se = FALSE)
```

```{r pruiwuifrgeghffffffffffffjhdessureg, echo=TRUE}
prediccion <- predict(modelo,datos, interval="confidence")
hist(prediccion, col = "green")
```

5. Si tuviera que eliminar alguna o algunas de las variables con la esperanza de que mejore la predicci´on ¿Cu´al o cu´ales de las variables eliminar´ıa? ¿El nuevo modelo mejora la predicci´on?

Eliminaria del modelo X, Educacion, Genero, casado, etnicidad. solo dejaria Ingreso, Limite, CalifCredit, Tarjetas, Edad y Estudiante, ya que mostrar significancia para predecir la variable en estudio.

```{r pruiwuifrgeghfjhdggggggggggggggessureg, echo=TRUE}
modelo <- lm(Balance ~ Ingreso + Limite  + CalifCredit + Tarjetas + Edad + Estudiante, data = datos)
modelo
```


```{r pruiwuifrgeghiiiiiiiiiiiiiiifjhdessureg, echo=TRUE}
modelo <- lm(Balance ~ Ingreso + Limite  + CalifCredit + Tarjetas + Edad + Estudiante, data = datos)

numero.predictoras <- dim(datos)[2] - 1
# Hace la Predicción
prediccion <- predict(modelo, ttesting)
# Medición de precisión
pre.lm <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.lm
```

La estimacion del modelo reducido tiene un error absoluto estimado de + (mas) o (-) 87.20528 dolares, inferior 94.58605 dolares en la estimacion final del Balance de la deuda en tarjetas de credito en el modelo completo, esto se explica porque al incluirse variables solo significativas el modelo no genera overfitting y permite eliminar variables que no aportan a la estimacion. El error relativo indica que el error de estimacion es aproximado de 11,48%, respecto al 12,68% y ademas la correlacion entre el valor real y el valor predicho es 0.9859838, respecto a 0.9842869, es decir, el modelo reducido se desmpena mejor. 


```{r pruiwuifrgeghfjhdessfdtgfdsgureg, echo=TRUE}
# Gráfico real vs predicción, con curva de mejor ajuste lineal
g <- plot.real.prediccion(ttesting$Balance, prediccion, modelo = "Regresión Lineal")
g + geom_smooth(method = lm, size = 0.4, color = "red", se = FALSE)
```


Pregunta 2: Un cliente nos contrata para estudiar una posible oportunidad de negocio, y para ver si le es rentable quiere una predicci´on de las ventas potenciales de asientos de ni˜nos para autos en su tienda. Para ello hacemos uso de los datos AsientosNinno.csv los cual contienen detalles de ventas de asientos de ni˜nos para auto en una serie de tiendas similares a las del cliente, y adem´as los datos incluyen variables que definen caracter´ısticas de la tienda y su localidad.
La tabla de datos est´a formada por 400 filas y 11 columnas. Seguidamente se explican las variables que conforman la tabla.

1. Cargue la tabla de datos en R. En caso de ser necesario, recodificar las variables de forma adecuada. Seleccione la variable a predecir, y para medir el error tome un 15 % de la tabla de datos.


```{r pruiwuifrgeghfjhdessukhkhkhkhkhreg, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase8")
datos<-read.csv("AsientosNinno.csv",sep=';',dec='.',header=T)
str(datos)

```

```{r pruiwuifrjdhfjmgmhcfmhdessureg, echo=TRUE}
suppressMessages(suppressWarnings(library(FactoMineR)))
suppressMessages(suppressWarnings(library(car)))
Atipicos<-(Boxplot(~Ventas, data=datos, id.method="y",col="Blue")) #Monto promedio de deuda en tarjeta de cr´edito del cliente, en d´olares
```


```{r pueyfifihhhhhjfjjiuwefguiwefhec, echo=TRUE}
# Elimino variables categóricas
datos2 <- datos[,-c(1,8)] ##verificar correlaciones con variables numericas
head(datos2)
```

```{r pueyfiffugiweuyfioeuyfgioeihhhhhjfjec, echo=TRUE}
library(corrplot)
matriz.correlacion<-cor(datos2)
corrplot(matriz.correlacion)
```

No hay mucha correlacion entre variables numericas predictoras.

```{r pueyfifihhhdhgiufheekgjhhjfjec, echo=TRUE}
muestra <- sample(1:nrow(datos),floor(nrow(datos)*0.15))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
nrow(ttesting)
nrow(taprendizaje)
```

2. Aplique los modelos de regresi´on lineal m´ultiple, regresi´on Ridge y regresi´on Lasso incluyendo todas las variables predictoras. ¿Se anulan coeficientes para el caso de regresi´on Lasso?

En el caso de LASSO como se observara en la estimacion del punto 3, se eliminan PrecioCompt, Ingreso, Publicidad, Poblacion, CalidadEstantMedio, Edad, Educacion, Urbano y USA. Generan estimadores que aproximan a cero, dada la poca cantidad de variables que quedan, es bastante presumible que el caso ideal de Lasso optimo termine asemejando a una regresion clasica

3. ¿Qu´e error se obtiene sobre la tabla de training para los 3 modelos generados anteriormente? ¿Cu´al considera que es el mejor seg´un la comparaci´on anterior?

Se aplican los modelos regresion lineal multiple, ridge y lasso, se generan varias simulaciones adicionales para mostrar un poco mas el comportamiento del lambda.

#Multiple
```{r pruiwuifrgdjflkjherklfjeghfjhdessureg, echo=TRUE}
modelo <- lm(Ventas ~ ., data = datos)
modelo 
```


```{r pruiwuifrgedfuwegfhgfgeghfjhdessureg, echo=TRUE}
summary(modelo)
```

```{r pruiwuifrgegdfhrthrtrhfjhdessureg, echo=TRUE}
# Calcula el modelo usando solo los datos de training
modelo.lm <- lm(Ventas~., data = taprendizaje)
modelo.lm
```

```{r pruiwuifrgeghfjhdnhetyessureg, echo=TRUE}
numero.predictoras <- dim(datos)[2] - 1
# Hace la Predicción
prediccion <- predict(modelo.lm, ttesting)
# Medición de precisión
pre.lm <- indices.precision(ttesting$Ventas, prediccion,numero.predictoras)
pre.lm
```

```{r pruiwuifrgsadfasfweeghfjhdessureg, echo=TRUE}
# Gráfico real vs predicción, con curva de mejor ajuste lineal
g <- plot.real.prediccion(ttesting$Ventas, prediccion, modelo = "Regresión Lineal")
g + geom_smooth(method = lm, size = 0.4, color = "red", se = FALSE)
```

```{r pruiwuifrgeghfjhdessurfgefhkjehfeeg, echo=TRUE}
prediccion <- predict(modelo,datos, interval="confidence")
hist(prediccion, col = "green")
```

###Ridge

```{r pruiwuifrgeghfjhdhdsgjsgdfessureg, echo=TRUE}
# La siguiente instrucción construye una matriz con los predictores
x<-model.matrix(Ventas~.,datos)
head(x)
```

```{r pruiwuifrgeghfjhdfgdgrtghdessureg, echo=TRUE}
# Debemos eliminar la columna 1
x<-model.matrix(Ventas~.,datos)[,-c(1,2)]
head(x)
# La siguiente instrucción construye la variable a predecir
y<-datos$Ventas
```

```{r pruiwuifrgeghfjhdrfjkhjhfessureg, echo=TRUE}
library(glmnet)
```

```{r pruiwuifrgeghfjhdewhwhessureg, echo=TRUE}
ridge.mod<-glmnet(x,y,alpha=0)
dim(coef(ridge.mod))
```

```{r pruiwuifrgeghfjhdethtyujytjssureg, echo=TRUE}
coef(ridge.mod)
```

```{r pruiwuifrgeghfjyjdytyjdjyhdessureg, echo=TRUE}
ridge.mod$lambda
```

```{r pruiwuifrgeghfjgfhdghdfhhdessureg, echo=TRUE}
plot(ridge.mod,"lambda", label=TRUE)
```

```{r pruiwuifrfdhdhdjhjgeghfjhdessureg, echo=TRUE}
ridge.mod$lambda[5]
log(ridge.mod$lambda[5])
coef(ridge.mod)[,5]  # Lambda más grande penaliza más tienden a ser los beta más pequeños
```

```{r pruiwuifrgeghfjhaergregrtdessureg, echo=TRUE}
plot(ridge.mod,"lambda", label=TRUE)
abline(v = log(ridge.mod$lambda[5]), col="blue", lwd=4, lty=3)
```

```{r pruiwuifrgeghhrgkhgjrhgfjhdessureg, echo=TRUE}
log(ridge.mod$lambda[70])
coef(ridge.mod)[,70]  # Lambda más grande penaliza más tienden a ser los beta más pequeños
```

```{r pruiwuifrgeghdesfeyfuyieufyiusureg, echo=TRUE}
plot(ridge.mod,"lambda", label=TRUE)
abline(v = log(ridge.mod$lambda[70]), col="blue", lwd=4, lty=3)
```

```{r pruiwugeghfjhdessureg, echo=TRUE}
datosx<-model.matrix(Ventas~.,datos)[,-c(1,2)]
pred<-predict(ridge.mod,s=ridge.mod$lambda[5],newx=datosx)
# Medición de precisión
numero.predictoras <- dim(datosx)[2]-1
pre.ridge <- indices.precision(datos$Ventas,pred,numero.predictoras)
pre.ridge
```

```{r pruiwuifrgeefergegerhghdessureg, echo=TRUE}
pred<-predict(ridge.mod,s=ridge.mod$lambda[70],newx=datosx)
# Medición de precisión
numero.predictoras <- dim(datosx)[2]-1
pre.ridge <- indices.precision(datos$Ventas,pred,numero.predictoras)
pre.ridge
```


```{r pruiwuifrgeghsshgjgjjhgjmjghureg, echo=TRUE}
# Usando validación cruzada para determinar el mejor Lambda
sal.cv<-cv.glmnet(x,y,alpha=0)
plot(sal.cv)
```

```{r pruiwuifrghdesjhioefuwiofuwosureg, echo=TRUE}
mejor.lambda<-sal.cv$lambda.min
mejor.lambda
```

```{r pruiwuifrgertergterghfjhdreg, echo=TRUE}
log(mejor.lambda)
```

```{r pruiwuifxthyrysrsrghdessureg, echo=TRUE}
coef(ridge.mod)[,which(ridge.mod$lambda==mejor.lambda)]
```

```{r pruiwuifrghdeewwioeueiowussureg, echo=TRUE}
plot(ridge.mod,"lambda", label=TRUE)
abline(v = log(mejor.lambda), col="blue", lwd=4, lty=3)
```

```{r pruiwuifrgedessjgjdjdtjdureg, echo=TRUE}
pred<-predict(ridge.mod,s=mejor.lambda,newx=datosx)
# Medición de precisión
numero.predictoras <- dim(datosx)[2]-1
pre.ridge <- indices.precision(datos$Ventas,pred,numero.predictoras)
pre.ridge
```


###LASSO

```{r pruiwuifrggfgffgfgfgfeghfjhdreg, echo=TRUE}
# Debemos eliminar la columna 1
x<-model.matrix(Ventas~.,datos)[,-c(1,2)]
head(x)
# La siguiente instrucción construye la variable a predecir
y<-datos$Ventas
```

```{r pruiwuifrgeghfjhdesg, echo=TRUE}
library(glmnet)

lasso.mod<-glmnet(x,y,alpha=1) 
dim(coef(lasso.mod))
```

```{r pruiwuifrgeghfjreg, echo=TRUE}
coef(lasso.mod)
```


```{r pruiwuifrghdfhdfhdfhbeghfssureg, echo=TRUE}
lasso.mod$lambda
```

```{r pruiwuifrgeghfjhdrkhkhkghkhheg, echo=TRUE}
plot(lasso.mod,"lambda", label=TRUE)
```

```{r pruiwrgeghfjhdeseg, echo=TRUE}
lasso.mod$lambda[5]
log(lasso.mod$lambda[5])
coef(lasso.mod)[,5]  # Lambda más grande penaliza más tienden a ser los beta más pequeños
```


```{r pruiwuifrgjhfgsdhgdrsyhrsdessureg, echo=TRUE}
plot(lasso.mod,"lambda", label=TRUE)
abline(v = log(lasso.mod$lambda[5]), col="blue", lwd=4, lty=3)
```

```{r pruiwuifrggxnfxfeghfjhureg, echo=TRUE}
lasso.mod$lambda[60]
log(lasso.mod$lambda[60])
coef(lasso.mod)[,60]  # Lambda más grande penaliza más tienden a ser los beta más pequeños
```

```{r pruiwuifrgeggfngxfngxfnhfssureg, echo=TRUE}
plot(lasso.mod,"lambda", label=TRUE)
abline(v = log(lasso.mod$lambda[60]), col="blue", lwd=4, lty=3)
```

```{r pruiwuifrgjhdedhfkjhgkhgkjssureg, echo=TRUE}
datosx<-model.matrix(Ventas~.,datos)[,-c(1,2)]
pred<-predict(lasso.mod,s=lasso.mod$lambda[5],newx=datosx)
# Medición de precisión
numero.predictoras <- dim(datosx)[2]-1
pre.lasso <- indices.precision(datos$Ventas,pred,numero.predictoras)
pre.lasso
```

```{r pruiwueghfjhdessureg, echo=TRUE}
pred<-predict(lasso.mod,s=lasso.mod$lambda[60],newx=datosx)
# Medición de precisión
numero.predictoras <- dim(datosx)[2]-1
pre.lasso <- indices.precision(datos$Ventas,pred,numero.predictoras)
pre.lasso
```

El error en este caso se mide entre otros por la raiz del error cuadratico medio. Ya que lo que indica este coeficiente es que la estimacion del modelo tiene un error absoluto estimado de + (mas) o (-) 1180 unidades de asientos vendidos en el caso de regresion multiple, contra + (mas) o (-) 1047 unidades de asientos vendidos en el caso de regresion Ridge, y + (mas) o (-) 1018 unidades de asientos vendidos en el caso de regresion Lasso. El error relativo indica que el error de estimacion es aproximado de 11,46% y ademas la correlacion entre el valor real y el valor predicho es 0.9283687 en la regresion multiple. Por su parte en Ridge, el error relativo indica que el error de estimacion es aproximado de 10,96% y ademas la correlacion entre el valor real y el valor predicho es 0.9340148 en la regresion multiple.Finalmente, en Lasso, el error relativo indica que el error de estimacion es aproximado de 10,72% y ademas la correlacion entre el valor real y el valor predicho es 0.9345484 en la regresion multiple.Curiosamente esto indica que el mejor ajuste se encuentra en la regresion de Lasso, para el caso de training, cabe indicar que las diferencias no resultan significativas, por lo que puede estar asociado a la seleccion de training vs test.


4. ¿En regresi´on Lasso, qu´e valor de λ tomar´ıa si se le pidiera obtener un modelo que no le de tanta importancia al error de predicci´on pero que sea mucho m´as f´acil de interpretar (es decir que a´un m´as coeficientes de la regresi´on sean nulos)? Genere dicho modelo, muestre los coeficientes y las medidas de error.


```{r pruiwrgeghfjhdessureg, echo=TRUE}
# Validación Cruzada
sal.cv<-cv.glmnet(x,y,alpha=1) 
plot(sal.cv)
```

```{r pruiwuifrgeghfjsureg, echo=TRUE}
mejor.lambda<-sal.cv$lambda.min
mejor.lambda
```


```{r pruiwuifrgeghsfhgfdhhhsureg, echo=TRUE}
log(mejor.lambda)
```

```{r pruiwuifrgeghfjhdessg, echo=TRUE}
coef(lasso.mod)[,which(lasso.mod$lambda==mejor.lambda)]
```

```{r pruiwuifrgeghfjfdhgkjrgherghhdreg, echo=TRUE}
plot(lasso.mod,"lambda", label=TRUE)
abline(v = log(mejor.lambda), col="blue", lwd=4, lty=3)
```

```{r pruiwuifrgeghfjhreg, echo=TRUE}
pred<-predict(lasso.mod,s=mejor.lambda,newx=datosx)
# Medición de precisión
numero.predictoras<- dim(datosx)[2]-1
numero.predictoras
```

```{r pruiwuifrgeghfjhdeg, echo=TRUE}
pre.lasso <- indices.precision(datos$Ventas,pred,numero.predictoras)
pre.lasso
```

El mejor lambda es de 0.003922837 y se genera en la grafica (mejor.lambda) en -5.54094.


Pregunta 3: La Tabla de Datos uscrime.csv contiene el c´alculo de´ındice de cr´ımenes violentos por habitante en Estados Unidos, como son el asesinato, la violaci´on, el robo y asalto. Las variables incluidas son, entre otras, el porcentaje de la poblaci´on considerada urbana, la renta media de la familia, la participaci´on de las fuerzas del orden, el n´umero de polic´ıas per c´apita, el porcentaje de los oficiales asignados a las unidades de la droga. La variable a predecir es ViolentCrimesPerPop (Per Capita Violent Crimes in US). Usando un 67 % de esta tabla para Tabla de Aprendizaje y el restante 33 % para Tabla de Testing efectue lo siguiente:

1. Construya un modelo predictivo para la variable ViolentCrimesPerPop usando una Regresi´on Lineal M´ultiple con la funci´on lm(...) en la Tabla de Aprendizaje y calcule Error Est´andar de los Residuos para este modelo, adem´as calcule el Error Cuadr´atico Medio y el Error Relativo para la Tabla de Testing.

```{r piwuifrgeghfjhdessureg, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase8")
datos<-read.csv("uscrime.csv",dec='.',header=T)
str(datos)
```

```{r pruiwuifsfsdgdfhjfghrjdhfjhdessureg, echo=TRUE}
suppressMessages(suppressWarnings(library(FactoMineR)))
suppressMessages(suppressWarnings(library(car)))
Atipicos<-(Boxplot(~ViolentCrimesPerPop, data=datos, id.method="y",col="Blue")) 
```

```{r pueyfifihhhgsfwugfhhjfjec, echo=TRUE}
library(corrplot)
matriz.correlacion<-cor(datos)
corrplot(matriz.correlacion)
```

```{r pueyfifihhhhfgwfgjwfhhjfjec, echo=TRUE}
muestra <- sample(1:nrow(datos),floor(nrow(datos)*0.33))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
nrow(ttesting)
nrow(taprendizaje)
```


```{r pruiwuifsdkajhskajhfkahfrgeghfssureg, echo=TRUE}
modelo <- lm(ViolentCrimesPerPop ~ ., data = datos)
modelo 
```


```{r pruiwughfjhdessureg, echo=TRUE}
summary(modelo)
```

```{r pruiwuihfjhdessureg, echo=TRUE}
# Calcula el modelo usando solo los datos de training
modelo.lm <- lm(ViolentCrimesPerPop~., data = taprendizaje)
modelo.lm
```

```{r pruiwuifrgegtu5tueueuhfjhdessureg, echo=TRUE}
numero.predictoras <- dim(datos)[2] - 1
# Hace la Predicción
prediccion <- predict(modelo.lm, ttesting)
# Medición de precisión
pre.lm <- indices.precision(ttesting$ViolentCrimesPerPop, prediccion,numero.predictoras)
pre.lm
```

```{r pruiwuifrgeghfjhdeyjjytjytyssureg, echo=TRUE}
# Gráfico real vs predicción, con curva de mejor ajuste lineal
library(ggplot2)
g <- plot.real.prediccion(ttesting$ViolentCrimesPerPop, prediccion, modelo = "Regresión Lineal")
g + geom_smooth(method = lm, size = 0.4, color = "red", se = FALSE)
```

```{r pruiwuifrgeghfjhitophitpohidessureg, echo=TRUE}
prediccion <- predict(modelo,datos, interval="confidence")
hist(prediccion, col = "green")
```

###Ridge

```{r pruiwuifrgeghfjhdjrtiojhoijessureg, echo=TRUE}
# La siguiente instrucción construye una matriz con los predictores
x<-model.matrix(ViolentCrimesPerPop~.,datos)
head(x)
```

```{r pruiwuifrgeghfhjitrojhrtjhortjjhdessureg, echo=TRUE}
# Debemos eliminar la columna 1
x<-model.matrix(ViolentCrimesPerPop~.,datos)[,-c(103)]
head(x)
# La siguiente instrucción construye la variable a predecir
y<-datos$ViolentCrimesPerPop
```

```{r pruiwuifrgeghfjhojrgopeeopruiopedessureg, echo=TRUE}
library(glmnet)
```

```{r pruiwuifrgeghfjhdesfretgheiorgheriosureg, echo=TRUE}
ridge.mod<-glmnet(x,y,alpha=0)
dim(coef(ridge.mod))
```

```{r pruiwuifrgeghfjhdesreytgkerjhrlkjrtsureg, echo=TRUE}
coef(ridge.mod)
```

```{r pruiwuifrgeghfjhhbkjsefhsjhdessureg, echo=TRUE}
ridge.mod$lambda
```

```{r pruiwuifrgeghfjhdesjefhejherhgsureg, echo=TRUE}
plot(ridge.mod,"lambda", label=TRUE)
```

```{r pruiwuifrgeghfdgerrhrjhdessureg, echo=TRUE}
ridge.mod$lambda[5]
log(ridge.mod$lambda[5])
coef(ridge.mod)[,5]  # Lambda más grande penaliza más tienden a ser los beta más pequeños
```

```{r pruiwuifrgeghfjhdudfuhijessureg, echo=TRUE}
plot(ridge.mod,"lambda", label=TRUE)
abline(v = log(ridge.mod$lambda[5]), col="blue", lwd=4, lty=3)
```

```{r pruiwuifrgeghfgjhgggjhdessureg, echo=TRUE}
log(ridge.mod$lambda[70])
coef(ridge.mod)[,70]  # Lambda más grande penaliza más tienden a ser los beta más pequeños
```

```{r pruiwuifrgeghfjhdessfjjdfhfhgureg, echo=TRUE}
plot(ridge.mod,"lambda", label=TRUE)
abline(v = log(ridge.mod$lambda[70]), col="blue", lwd=4, lty=3)
```

```{r pruiwuifhfjhdessureg, echo=TRUE}
datosx<-model.matrix(ViolentCrimesPerPop~.,datos)[,-c(103)]
pred<-predict(ridge.mod,s=ridge.mod$lambda[5],newx=datosx)
# Medición de precisión
numero.predictoras <- dim(datosx)[2]-1
pre.ridge <- indices.precision(datos$ViolentCrimesPerPop,pred,numero.predictoras)
pre.ridge
```

```{r pruiwuifrgedbxbfgbdfhfdhessureg, echo=TRUE}
pred<-predict(ridge.mod,s=ridge.mod$lambda[70],newx=datosx)
# Medición de precisión
numero.predictoras <- dim(datosx)[2]-1
pre.ridge <- indices.precision(datos$ViolentCrimesPerPop,pred,numero.predictoras)
pre.ridge
```



```{r pruiwuifrgegeg, echo=TRUE}
# Usando validación cruzada para determinar el mejor Lambda
sal.cv<-cv.glmnet(x,y,alpha=0)
plot(sal.cv)
```

```{r pruiwuifrgessureg, echo=TRUE}
mejor.lambda<-sal.cv$lambda.min
mejor.lambda
```

```{r pruiwuifrgeghfddffffjhdessureg, echo=TRUE}
log(mejor.lambda)
```

```{r pruiwuifrgeghfdfnhkdnjfmjhdessureg, echo=TRUE}
coef(ridge.mod)[,which(ridge.mod$lambda==mejor.lambda)]
```

```{r pruiwuifrgeghfjhdedbjfjdghfssureg, echo=TRUE}
plot(ridge.mod,"lambda", label=TRUE)
abline(v = log(mejor.lambda), col="blue", lwd=4, lty=3)
```

```{r pruiwuifrgeghfjhdhfhrtessureg, echo=TRUE}
pred<-predict(ridge.mod,s=mejor.lambda,newx=datosx)
# Medición de precisión
numero.predictoras <- dim(datosx)[2]-1
pre.ridge <- indices.precision(datos$ViolentCrimesPerPop,pred,numero.predictoras)
pre.ridge
```


###LASSO

```{r pruiwuifrgeghfjtrhrhhtrhhrhbgjkhhdessureg, echo=TRUE}
# Debemos eliminar la columna 1
x<-model.matrix(ViolentCrimesPerPop~.,datos)[,-c(103)]
head(x)
# La siguiente instrucción construye la variable a predecir
y<-datos$ViolentCrimesPerPop
```

```{r pruiwuifrgeghfjhdesjgkljgkljgsureg, echo=TRUE}
library(glmnet)

lasso.mod<-glmnet(x,y,alpha=1) 
dim(coef(lasso.mod))
```

```{r pruiwuifrgeghfjhdessurerkjkljkljgg, echo=TRUE}
coef(lasso.mod)
```

```{r pruiwuifrgeghfjhdessushfghjsdhreg, echo=TRUE}
lasso.mod$lambda
```

```{r pruiwuifrgeghfeyfuirytuytyjhdessureg, echo=TRUE}
plot(lasso.mod,"lambda", label=TRUE)
```

```{r pruiwuifrgeghfjhfgjkdfhgjkhdgjhdessureg, echo=TRUE}
lasso.mod$lambda[5]
log(lasso.mod$lambda[5])
coef(lasso.mod)[,5]  # Lambda más grande penaliza más tienden a ser los beta más pequeños
```

```{r pruiwuifrgeghfjhhgfgjhfgfgdessureg, echo=TRUE}
plot(lasso.mod,"lambda", label=TRUE)
abline(v = log(lasso.mod$lambda[5]), col="blue", lwd=4, lty=3)
```

```{r pruiwuifrgeghfjhdessdhfjksdfhkjshfureg, echo=TRUE}
lasso.mod$lambda[60]
log(lasso.mod$lambda[60])
coef(lasso.mod)[,60]  # Lambda más grande penaliza más tienden a ser los beta más pequeños
```

```{r pruiwuifrgeghfjhdessureejyekjyfg, echo=TRUE}
plot(lasso.mod,"lambda", label=TRUE)
abline(v = log(lasso.mod$lambda[60]), col="blue", lwd=4, lty=3)
```

```{r pruiwuifrgeghfjhdessdfjksfksjfhJKshfkjshfksjfhureg, echo=TRUE}
datosx<-model.matrix(ViolentCrimesPerPop~.,datos)[,-c(103)]
pred<-predict(lasso.mod,s=lasso.mod$lambda[5],newx=datosx)
# Medición de precisión
numero.predictoras <- dim(datosx)[2]-1
pre.lasso <- indices.precision(datos$ViolentCrimesPerPop,pred,numero.predictoras)
pre.lasso
```

```{r pruiwuifrgeghfjhbdjfhehsjdkghjdessureg, echo=TRUE}
pred<-predict(lasso.mod,s=lasso.mod$lambda[60],newx=datosx)
# Medición de precisión
numero.predictoras <- dim(datosx)[2]-1
pre.lasso <- indices.precision(datos$ViolentCrimesPerPop,pred,numero.predictoras)
pre.lasso
```


```{r pruiwuifrgeghfjhdessujhsdffffkfjdreg, echo=TRUE}
# Validación Cruzada
sal.cv<-cv.glmnet(x,y,alpha=1) 
plot(sal.cv)
```

```{r pruiwuifrgeghfjhdesgggggggggggggggggggsureg, echo=TRUE}
mejor.lambda<-sal.cv$lambda.min
mejor.lambda
```

```{r pruiwuifrgdddddddddddddddddddddddddeghfjhdessureg, echo=TRUE}
log(mejor.lambda)
```

```{r pruiwuifrgeghfjhdessuaaaaaaaaaaaaaaaaaareg, echo=TRUE}
coef(lasso.mod)[,which(lasso.mod$lambda==mejor.lambda)]
```

```{r pruiwuifrgeghfjhdessurmmmmmmmmmmmmmmmmmmmmmmmeg, echo=TRUE}
plot(lasso.mod,"lambda", label=TRUE)
abline(v = log(mejor.lambda), col="blue", lwd=4, lty=3)
```

```{r pruiwuifrgeghsssssssssssssssssssssfjhdessureg, echo=TRUE}
pred<-predict(lasso.mod,s=mejor.lambda,newx=datosx)
# Medición de precisión
numero.predictoras<- dim(datosx)[2]-1
numero.predictoras
```

```{r pruiwuifrgeghfjhddddddddddddddddddessureg, echo=TRUE}
pre.lasso <- indices.precision(datos$ViolentCrimesPerPop,pred,numero.predictoras)
pre.lasso
```

###Elastic Net

```{r pruiwuifrgeghfjttttttttttttthdessureg, echo=TRUE}
# Debemos eliminar la columna 1
x<-model.matrix(ViolentCrimesPerPop~.,datos)[,-c(103)]
head(x)
# La siguiente instrucción construye la variable a predecir
y<-datos$ViolentCrimesPerPop
```

```{r pruiwuifrgeghfyyyyyyyyyyyyyyyyyyyyyjhdessureg, echo=TRUE}
library(glmnet)
datosx<-model.matrix(ViolentCrimesPerPop~.,datos)[,-c(103)]

v.alpha<-c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)

for(ss in v.alpha) {
  cat("========ELASTIC NET========\n")
  cat("Alpha=",ss,"\n")
  net.mod<-glmnet(x,y,alpha=ss)
  sal.cv<-cv.glmnet(x,y,alpha=ss) 
  mejor.lambda<-sal.cv$lambda.min
  pred<-predict(net.mod,s=mejor.lambda,newx=datosx)
  res<-MSE(pred,datos$ViolentCrimesPerPop)
  cat("MSE",res,"\n")
}
```

5. ¿Cu´al m´etodo usar´ıa con base en la informaci´on obtenida en los ejercicios anteriores?

En este caso el error cuadratico medio y error relativo mas bajo parece ser nuevamente la regresion de Lasso, la diferencia resulta no muy grande, pero mejor.


Pregunta 4:
1. Programe en R una funci´on lm2(...) que recibe como par´ametro una tabla de aprendizaje y retorna un modelo de Regresi´on Lineal, es decir, calcula y retorna β = (XtX) −1Xt y.

```{r pruiwuifrgeghfkkkkkkkkkkkkkkkkkkkjhdessureg, echo=TRUE}
x<-model.matrix(ViolentCrimesPerPop~.,taprendizaje)[,-c(103)]
y<-datos$ViolentCrimesPerPop

lm2<-function(X,Y){
  n<-nrow(X)
  k<-ncol(X)
  Constante<-seq(1,1,length.out =n)
  
  datos1<-data.frame(Constante,X)
  
  X<-as.matrix(datos1)
  Y<-as.matrix(Y)

  XtX<-t(X)%*%X
  XtX.inv<-solve(XtX)
  XY<-t(X)%*%Y

  Betas<-solve(t(X)%*%X)%*%(t(X)%*%Y)

  B<-data.frame(Coeficientes=Betas)
  B
  }
lm2(datos[,1:102], datos[,103])

```

2. Programe en R una funci´on predict2(...) que recibe como par´ametro el modelo construido en la pregunta anterior, una tabla de testing de modo tal que retorna la predicci´on para esta tabla de testing.


```{r pruiwucccccccccccifrgeghfjhdessureg, echo=TRUE}
# numero.predictoras <- dim(datos)[2] - 1
# # Hace la Predicción
# prediccion <- predict(modelo.lm, ttesting)
# # Medición de precisión
# pre.lm <- indices.precision(ttesting$ViolentCrimesPerPop, prediccion,numero.predictoras)
# pre.lm

x<-model.matrix(ViolentCrimesPerPop~.,ttesting)[,-c(103)]
y<-datos$ViolentCrimesPerPop


predict2<-function(x,y){
  n<-nrow(x)
  k<-ncol(x)
  Constante<-seq(1,1,length.out =n)
  
  datos1<-data.frame(Constante,x)
  
  X<-as.matrix(datos1)
  Y<-as.matrix(y)

  XtX<-t(X)%*%X
  XtX.inv<-solve(XtX)
  XY<-t(X)%*%Y

  Betas<-solve(t(X)%*%X)%*%(t(X)%*%Y)

    # Suma de Cuadrados
  
  Syy<-t(Y)%*%Y-nrow(Y)*mean(Y)^2
  SSE=t(Y)%*%Y - t(Betas)%*%XY
  SSR<-t(Betas)%*%XY-nrow(Y)*mean(Y)^2
  
  # Grados de libertad
  gl1=k
  gl2=nrow(Y)-(k+1)
  
  # test para Betas
  MSE=SSE/gl2
  Varianzas<-as.vector(MSE)*diag(XtX.inv)
  Desviaciones<-sqrt(Varianzas)
  diagonal<-diag(Desviaciones,k+1,k+1)

    t<-t(t(Betas)%*%solve(diagonal))
  
    v.p<-2*pt(abs(t),gl2,lower.tail=FALSE)

  estimaciones<-data.frame(Coeficientes=Betas,t_student = t,Valor_p=v.p)
  estimaciones
  }

predict2(datos[,1:102], datos[,103])
```
3. Usando la tabla de datos uscrime.csv compare los resultados de las funciones lm(...), lm2(...), predict(...) y predict2(...).
```{r pruiwuifrgeghfbbbbbbbbbbbbbjhdessureg, echo=TRUE}
lm <- lm(ViolentCrimesPerPop~., data = taprendizaje)
lm

prediccion <- predict(lm, ttesting)
head(prediccion)
```


4. Usando la tabla de datos uscrime.csv y la funci´on de R denominada system.time(...) compare los tiempos de ejecuci´on de las funciones lm(...), lm2(...), predict(...) y predict2(...).

```{r pruiwuifrgeghfjhdeoooooooooooooooossureg, echo=TRUE}
system.time(lm(ViolentCrimesPerPop~., data = taprendizaje))
system.time(predict(lm, ttesting))
system.time(lm2(datos[,1:102], datos[,103]))
system.time(predict2(datos[,1:102], datos[,103]))
```

Es mas rapido lm y predict.

Pregunta 5: Demuestre que la Regresi´on Ridge puede ser obtenida mediante Regresi´on Lineal cl´asica usando una versi´on aumentada de la tabla de datos de la siguiente manera: Se aumenta la tabla de datos X con p filas adicionales √λI; y se aumenta y con p ceros, es decir: Xe =

##Ver arhcivo adjunto

Pregunta 6:
(a) Supongamos que ejecutamos una regresi´on Ridge con par´ametro λ en una sola variable X, y se obtiene el coeficiente a. Ahora incluimos una copia exacta X? = X y volvemos a calcular la regresi´on Ridge. Demuestre que ambos coeficientes son id´enticos y calcule su valor. Demuestre en general que si m copias de la variable Xj son incluidas en la regresi´on Ridge, entonces sus coeficientes son todos iguales. Sugerencia: Considere matrices como las siguientes: X =

(b) ¿Qu´e pasa en Regresi´on Lasso? ¿Ocurre lo mismo?

##Ver arhcivo adjunto


Pregunta 7: En este ejercicio usaremos los datos (voces.csv). Se trata de un problema de reconocimiento de g´enero mediante el an´alisis de la voz y el habla. Esta base de datos fue creada para identificar una voz como masculina o femenina, bas´andose en las propiedades ac´usticas de la voz y el habla. El conjunto de datos consta de 3.168 muestras de voz grabadas, recogidas de hablantes masculinos y femeninos. Las muestras de voz se preprocesan mediante an´alisis

1. Cargue la tabla de datos voces.csv en R. No olvide recodificar la variable a predecir
como categ´orica.


```{r pruiwuifrgeghfjhdessupppppppppppppreg, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase3")
datos<-read.csv("voces.csv",dec='.',header=T)
str(datos)
datos$genero <- factor(datos$genero,ordered = TRUE) ##ya es un factor es una linea repetitiva pero que ordena 
```

```{r pruiwuifrjdhfjhdeufgwuifgessureg, echo=TRUE}
barplot(prop.table(table(datos$genero)),col=c("orange","blue","green"),main="Distribución de la variable por predecir")
```

2. Usando el comando sample de R genere al azar una tabla aprendizaje con un 80 % de los datos y con el resto de los datos genere una tabla de aprendizaje.

```{r pueyfifihhhhhjegfuewfgjeffjec, echo=TRUE}
muestra <- sample(1:nrow(datos),floor(nrow(datos)*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
nrow(ttesting)
nrow(taprendizaje)
```

3. Usando el m´etodo de Regresi´on Log´ıstica (con glm y glmnet) genere modelos predictivos para la tabla de aprendizaje. Luego para estos modelos calcule la matriz de confusi´on, la precisi´on, la precisi´on positiva, la precisi´on negativa, los falsos positivos, los falsos negativos, la acertividad positiva y la acertividad negativa.

```{r pueyfifijfjheifhreec, echo=TRUE}
indices.general <- function(MC) {
  precision.global <- sum(diag(MC))/sum(MC)
  error.global <- 1 - precision.global
  precision.categoria <- diag(MC)/rowSums(MC)
  precision.positiva <- MC[2, 2]/(MC[2, 2] + MC[2, 1])
  precision.negativa <- MC[1, 1]/(MC[1, 1] + MC[1, 2])
  falsos.positivos <- 1 - precision.negativa
  falsos.negativos <- 1 - precision.positiva
  asertividad.positiva <- MC[2, 2]/(MC[1, 2] + MC[2, 2])
  asertividad.negativa <- MC[1, 1]/(MC[1, 1] + MC[2, 1])
  res <- list(matriz.confusion = MC, precision.global = precision.global, error.global = error.global, 
              precision.categoria = precision.categoria, precision.positiva = precision.positiva, precision.negativa=precision.negativa, 
              falsos.positivos=falsos.positivos, falsos.negativos=falsos.negativos, asertividad.positiva=asertividad.positiva,
              asertividad.negativa=asertividad.negativa)
  names(res) <- c("Matriz de Confusión", "Precisión Global", "Error Global", "Precisión por categoría", "Precision Positiva", "Precision Negativa",
                  "Falsos Positivos", "Falsos Negativos", "Asertividad Positiva", "Asertividad Negativa")
  return(res)
}

```

```{r pueyffjrefierhfihghggsghruec, echo=TRUE}
library(corrplot)
library(glmnet)
library(dygraphs)
library(tidyverse)
```

```{r pueyffjresggrgrggtrhruec, echo=TRUE}
modelo <- glm(genero ~ . , data = taprendizaje, family = binomial)
probabilidades <- predict(modelo, ttesting, type = "response")
head(probabilidades)
```

```{r pueyffjresrgrregergghruec, echo=TRUE}
prediccion <- rep("No", dim(ttesting)[1])
prediccion[probabilidades > 0.5] = "Si"  # Porque 1=Si entonces P>=0.5 => Si
Actual <- ttesting$genero
## Matriz de Confusión
MC <- table(Actual, prediccion)
indices.general(MC)
```

4. Construya una tabla para los ´ındices anteriores que permita comparar el resultados de los m´etodos Regresi´on Log´ıstica Cl´asica, Ridge y Lasso ¿Cu´al m´etodo es mejor? Campare tambi´en con los resultados de las tareas anteriores. ¿Cu´al m´etodo es mejor?


#LASSO
```{r pueyffjrergrhgjghjesghruec, echo=TRUE}
x <- model.matrix(genero ~ ., taprendizaje)[,-1]
head(x)
y <- taprendizaje$genero
```

```{r pueyffjresghrgjkghjkrghruec, echo=TRUE}
datos.test <- model.matrix(genero~.,ttesting)[,-1]
modelo.lasso <- glmnet(x, y, alpha = 1, family = "multinomial") 
plot(modelo.lasso,"lambda", label=TRUE)
```

```{r pueyffjresghrrehjrhjrhgjhrguec, echo=TRUE}
modelo.lasso.cv <- cv.glmnet(x, y, alpha = 1, family = "multinomial")
plot(modelo.lasso.cv)
```

```{r pueyffjresfrefjhgjkghghruec, echo=TRUE}
mejor.lambda <- modelo.lasso.cv$lambda.min
mejor.lambda
```

```{r pueyffjrfherjhgjkrhgkesghruec, echo=TRUE}
prediccion <- predict(modelo.lasso.cv,datos.test,type="class",s=mejor.lambda)
Actual <- ttesting$genero
## Matriz de Confusión
MC <- table(Actual, prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

###Ridge
```{r pueyffferfgiurureyfurjresghruec, echo=TRUE}
x <- model.matrix(genero ~ ., taprendizaje)[,-1]
head(x)
y <- taprendizaje$genero
```

```{r pueyffjresghrugraeghjkaehgarkejhgrec, echo=TRUE}
datos.test <- model.matrix(genero~.,ttesting)[,-1]
modelo.ridge <- glmnet(x, y, alpha = 1, family = "multinomial") 
plot(modelo.ridge,"lambda", label=TRUE)
```

```{r pueyffjresghrewfhwejfhehuec, echo=TRUE}
modelo.ridge.cv <- cv.glmnet(x, y, alpha = 1, family = "multinomial")
plot(modelo.ridge.cv)
```

```{r pueyffjrfwefgfgjkehfesghruec, echo=TRUE}
mejor.lambda <- modelo.ridge.cv$lambda.min
mejor.lambda
```

```{r pueyffmbfmgblfglktghruec, echo=TRUE}
prediccion <- predict(modelo.ridge.cv,datos.test,type="class",s=mejor.lambda)
Actual <- ttesting$genero
## Matriz de Confusión
MC <- table(Actual, prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

4. Construya una tabla para los ´ındices anteriores que permita comparar el resultados de
los m´etodos Regresi´on Log´ıstica Cl´asica, Ridge y Lasso ¿Cu´al m´etodo es mejor? Campare
tambi´en con los resultados de las tareas anteriores. ¿Cu´al m´etodo es mejor?

```{r pressurek, echo=TRUE}
x <- data.frame("Modelo" = c("Regresion Logistica","Ridge","Lasso"), "Precision Global" = c(0.9763033,0.9763033, 0.9763033), "Error Global" = c(0.02369668,0.02369668,0.02369668), "precision positiva" = c(0.9803922, 0.9803922, 0.9803922), "precision negativa" = c(0.9724771, 0.9724771, 0.9724771), "falsos positivos" = c(0.02752294, 0.02752294, 0.02752294), "falsos negativos" = c(0.01960784, 0.01960784, 0.01960784), "asertividad positiva" = c(0.9708738, 0.9708738, 0.9708738), "asertividad negativa" = c(0.9814815, 0.9814815, 0.9814815))
x
```

Los tres modelos curiosamente dan resultados iguales pero analizando la precision global y por categorias estos tres modelos de regresion por igual logran estimar adecuadamente la diferencia en el genero de voz. El metodo trainRSVM "Radial" continua siendo el mas preciso y con menor error global. A pesar de ello bosques aleatorios (0.9763033), potenciaciacion (0.9731438) y xgboosting (0.9794629) se muestran como metodos significativamente precisos, tambien. De hecho, la diferencia respecto al SVM mencionado no resulta significativa. El metodo de Bayes posee el peor desempeno segun la precision global y el error, analizando la matriz de confusion ademas, se denota que este metodo tiene un exceso importante de datos confundidos. El mejor SVM para este ejercicio es con el default kernel, el radial. Posee una precision bastante alta de 0.9873618. Para este ejercicio parece ser el metodo el que mejor se ha ajustado. El arbol de decisio con una precision global de 0.9462875, estuvo mas bajo. Ademas otras estimaciones tardan mas, es decir,  redes tarda mas entre mas cantidad de nodos, pero la precision global y el error global en los tres casos de redes se mantienen entre 97 y 98%, y 2% y 3%, respectivamente. De los seis modelos (svm, arbol, 3 redes, kvecinos) tomando precision global como criterio principal y revisando un poco la precision de categorias, SVM radial en este caso tiene la precision mas alta , pero se denota que no existe diferencia significativa, ya que siguiendo la finalidad de este ejercicio se realizan distintas simulaciones para comparar. En la mayoria de los casos la precision de la red neuronal especialmente la de 4 nodos se acerca a la que mejor estimacion de svm radial, pero todas las estimaciones usando k vecinos y redes neuronales con distinta cantidad de nodos, han dado precisiones de entre 96,68% y 98,26% como ocurrio en el de 4 nodos contra 15 nodos, es decir, no se notan diferencias significativas. Los svm con otros kernels tambien han sido bastante acertados, de hecho, puede ser la muestra la que influya en la decision.


Pregunta 8: En esta pregunta utiliza los datos (tumores.csv). Se trata de un conjunto de datos de caracter´ısticas del tumor cerebral que incluye cinco variables de primer orden y ocho de textura y cuatro par´ametros de evaluaci´on de la calidad con el nivel objetivo. La variables son: Media, Varianza, Desviaci´on est´andar, Asimetr´ıa, Kurtosis, Contraste, Energ´ıa, ASM (segundo momento angular), Entrop´ıa, Homogeneidad, Disimilitud, Correlaci´on, Grosor, PSNR (Pico de la relaci´on se˜nal-ruido), SSIM (´Indice de Similitud Estructurada), MSE (Mean Square Error), DC (Coeficiente de Dados) y la variable a predecir tipo (1 = Tumor, 0 = No-Tumor). Realice lo siguiente:

```{r pruryjfhjel, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase2")
data2<-read.csv("tumores.csv",dec='.',header=T)
head(data2)
```

```{r presuweyruueyf8ryeioremaa, echo=TRUE}
library(caret)
data2$tipo <- factor(data1$tipo,ordered = TRUE)
data1 <- data2[,-1]
str(data1)
```

```{r pruiwuifrgegerhdessureg, echo=TRUE}
barplot(prop.table(table(data1$tipo)),col=c("orange","blue","green"),main="Distribución de la variable por predecir")
```
Ejercicio desbalanceado

```{r pressuueyremaa, echo=TRUE}
intrain <- createDataPartition(
  y = data1$tipo,
  p = .75,
  list = FALSE
)
str(intrain)
```

```{r prywteburemaa, echo=TRUE}
taprendizaje <- data1[ intrain,]
ttesting  <- data1[-intrain,]

nrow(taprendizaje)
nrow(ttesting)
```

2. Usando la funci´on indices.general(...) vista en clase para la tabla de testing calcule la matriz de confusi´on, la precisi´on global, el error global y la precisi´on de cada una de las clases. Construya una tabla para los ´ındices anteriores que permita comparar los resultados de los m´etodos Regresi´on Log´ıstica Cl´asica, Ridge y Lasso. ¿Cu´al m´etodo es mejor? Campare tambi´en con los resultados de las tareas anteriores. ¿Cu´al m´etodo es mejor?

```{r pueyffjrefjoiugouriotsghruec, echo=TRUE}
modelo <- glm(tipo ~ . , data = taprendizaje, family = binomial)
probabilidades <- predict(modelo, ttesting, type = "response")
head(probabilidades)
```

```{r pueyffjresgrgklrejglkrjgklhruec, echo=TRUE}
prediccion <- rep("No", dim(ttesting)[1])
prediccion[probabilidades > 0.5] = "Si"  # Porque 1=Si entonces P>=0.5 => Si
Actual <- ttesting$tipo
## Matriz de Confusión
MC <- table(Actual, prediccion)
indices.general(MC)
```


#LASSO
```{r pueyffjfhkghfjgkjgjrkljresghruec, echo=TRUE}
x <- model.matrix(tipo ~ ., taprendizaje)[,-1]
head(x)
y <- taprendizaje$tipo
```

```{r pueyffjresghmfnnbdfnbdfnbruec, echo=TRUE}
datos.test <- model.matrix(tipo~.,ttesting)[,-1]
modelo.lasso <- glmnet(x, y, alpha = 1, family = "multinomial") 
plot(modelo.lasso,"lambda", label=TRUE)
```

```{r pueyffjresghrgbkjgkerjglkerjguec, echo=TRUE}
modelo.lasso.cv <- cv.glmnet(x, y, alpha = 1, family = "multinomial")
plot(modelo.lasso.cv)
```

```{r pueyffjresgdvhgdjhfehhruec, echo=TRUE}
mejor.lambda <- modelo.lasso.cv$lambda.min
mejor.lambda
```

```{r pueyhgfjkwehfkehfffjresghruec, echo=TRUE}
prediccion <- predict(modelo.lasso.cv,datos.test,type="class",s=mejor.lambda)
Actual <- ttesting$tipo
## Matriz de Confusión
MC <- table(Actual, prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

###Ridge
```{r pueyffjresghrgjkerhggherhhruec, echo=TRUE}
x <- model.matrix(tipo ~ ., taprendizaje)[,-1]
head(x)
y <- taprendizaje$tipo
```

```{r pueyffjresghehfiehferjhruec, echo=TRUE}
datos.test <- model.matrix(tipo~.,ttesting)[,-1]
modelo.ridge <- glmnet(x, y, alpha = 1, family = "multinomial") 
plot(modelo.ridge,"lambda", label=TRUE)
```

```{r pueyffjresghretgjerjgrejgkruec, echo=TRUE}
modelo.ridge.cv <- cv.glmnet(x, y, alpha = 1, family = "multinomial")
plot(modelo.ridge.cv)
```

```{r pueyffjresgegfeghfehfejkhfjkehruec, echo=TRUE}
mejor.lambda <- modelo.ridge.cv$lambda.min
mejor.lambda
```

```{r pueyffjresghvdfgkjehfkjehfkjwehfruec, echo=TRUE}
prediccion <- predict(modelo.ridge.cv,datos.test,type="class",s=mejor.lambda)
Actual <- ttesting$tipo
## Matriz de Confusión
MC <- table(Actual, prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Los tres modelos presentan una precision global muy alta por encima de 0,98, de hecho la regresion logistica clasica tiene la precision global mas alta de todos los metodos incluyendo tareas pasadas con 0.9874214, pero tiene igualmente problemas identificando los no tumores al tener una precision por categoria en esto de 0.8750000 frente a un 0.9965986 cuando si es tumor. Lasso y ridge mantienen una precision global 0.9811321 que no tiene diferencia significativa respecto a la logistica. Para el caso de tumores la mejor prediccion, anteriormente fue ser con el metodo de bosques aleatorios con una precision global de 0.9842767, seguido de potenciacion con 0.9811321. Cabe resaltar que XGBoosting no logra distinguir bien la variacion en el problema y tiene la peor precision. Cabe destacar tambien que la precision por categoria es alta cuando existe tumor pero de menos de 0,90 cuando no hay tumor. Esto realmente siguiendo los resultados de tareas anteriores que falta datos de no tumores. El segundo peor metodo es el de BayesNinguno estimado, ademas LDA y QDA no estaban logrando ser estimados. Cabe resaltar que por tratarse de tumores los metodos en general no estan logrando estimar correctamente los casos de no tumor.Todos los kernels dan la misma matrix de confusion en el caso de SVM, excepto el linear que permite identificar ambos casos y tiene la precision global mas alta con 0.9716981, pero una asertividad negativa aun baja de 0.7777778.Comparando de forma sencillo los modelos mas acertados en las tareas anteriores, ya que se han dado varios intentos con resultados de toda clase. El SVM linear parece ser en este ejercicio el que mejor esta asimilando los datos para explicar la variabilidad del caso. Tiene una precision global bastante alta. De hecho, todos los casos probables de no tumor los identifica. Aun asi debe indicarse que se trata con tumores, lo implica que se necesita replantear el modelo, dado que se trata de tumores, lo que es mas importante, es probable que se requier un tamano de muestra mas grande para arrojar datos veridicos ya que en este caso los modelos no estan leyendo completamente bien los casos. En el caso de todos los modelos la precision por categoria ha sido especialmente debil al no detectar los no tumores, esto se explica probablemente por la falta de muestra en estos casos. 



Pregunta 9: En este ejercicio vamos a predecir n´umeros escritos a mano (Hand Written Digit Recognition), la tabla de de datos est´a en el archivo ZipData 2020.csv. En la figura siguiente se ilustran los datos:

1. Cargue la tabla de datos ZipData 2020.csv en R.

```{r pressrywerfefiyriouioqfhklfjureo, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase3")
data2<-read.csv("ZipData_2020.csv",sep=";",dec='.',header=T)
head(data2)
```

```{r preseewuifefferqfwuiyfhoruioweusureo, echo=TRUE}
str(data2)
```

```{r pruiwuifrfreqgegerghjhsjdhfjhdessureg, echo=TRUE}
barplot(prop.table(table(data2$Numero)), main="Distribución de la variable por predecir")
```

2. Usando los m´etodos Regresi´on Log´ıstica Cl´asica, Ridge y Lasso genere un modelos predictivos y los par´ametros que usted considere m´as conveniente para generar un modelo predictivo para la tabla ZipData 2020.csv usando el 80 % de los datos para la tabla aprendizaje y un 20 % para la tabla testing, luego calcule para los datos de testing la matriz de confusi´on, la precisi´on global y la precisi´on para cada una de las categor´ıas.
¿Son buenos los resultados? Explique.

```{r pueyffjressfrwehKFHWJKFHurec, echo=TRUE}
muestra <- sample(1:nrow(data2),floor(nrow(data2)*0.20))
ttesting <- data2[muestra,]
taprendizaje <- data2[-muestra,]

nrow(ttesting)
nrow(taprendizaje)
```

```{r pueyffjrerhgkrhghrkgjhjrgjhrsghruec, echo=TRUE}
modelo <- glm(Numero ~ . , data = taprendizaje, family = binomial)
probabilidades <- predict(modelo, ttesting, type = "response")
head(probabilidades)
```

```{r pueyffjresesfejkfhkjeshfeghruec, echo=TRUE}
prediccion <- rep("No", dim(ttesting)[1])
prediccion[probabilidades > 0.5] = "Si"  # Porque 1=Si entonces P>=0.5 => Si
Actual <- ttesting$Numero
## Matriz de Confusión
MC <- table(Actual, prediccion)
indices.general(MC)
```


#LASSO
```{r pueyffjresghreklgjkljgelkjlruec, echo=TRUE}
x <- model.matrix(Numero ~ ., taprendizaje)[,-1]
head(x)
y <- taprendizaje$Numero
```

```{r pueyffjreehjkhfkjwehfkjwehsghruec, echo=TRUE}
datos.test <- model.matrix(Numero~.,ttesting)[,-1]
modelo.lasso <- glmnet(x, y, alpha = 1, family = "multinomial") 
plot(modelo.lasso,"lambda", label=TRUE)
```

```{r pueyffjreshfkejfhehfkjghruec, echo=TRUE}
modelo.lasso.cv <- cv.glmnet(x, y, alpha = 1, family = "multinomial")
```

```{r pueyffjurfhuierhgehgerjghjkeresghruec, echo=TRUE}
mejor.lambda <- modelo.lasso.cv$lambda.min
mejor.lambda
```

```{r pueyffjresejkfherfhekjfghruec, echo=TRUE}
prediccion <- predict(modelo.lasso.cv,datos.test,type="class",s=mejor.lambda)
Actual <- ttesting$Numero
## Matriz de Confusión
MC <- table(Actual, prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

###Ridge
```{r pueyffjreegfjkerghfejhghfejhfgjhsghruec, echo=TRUE}
x <- model.matrix(Numero ~ ., taprendizaje)[,-1]
head(x)
y <- taprendizaje$Numero
```

```{r pueyffjhavjhdgwejhgwresghruec, echo=TRUE}
library(glmnet)
datos.test <- model.matrix(Numero~.,ttesting)[,-1]
modelo.ridge <- glmnet(x, y, alpha = 1, family = "multinomial") 
plot(modelo.ridge,"lambda", label=TRUE)
```

```{r pueyffjresghrukhtjtrjhrtghec, echo=TRUE}
modelo.ridge.cv <- cv.glmnet(x, y, alpha = 1, family = "multinomial")
plot(modelo.ridge.cv)
```

```{r pueyffjresghgewgfwfghfgjhruec, echo=TRUE}
mejor.lambda <- modelo.ridge.cv$lambda.min
mejor.lambda
```

```{r pueyhifherifgefguywgfyffjresghruec, echo=TRUE}
prediccion <- predict(modelo.ridge.cv,datos.test,type="class",s=mejor.lambda)
Actual <- ttesting$Numero
## Matriz de Confusión
MC <- table(Actual, prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```


3. Compare los resultados con los obtenidos en las tareas anteriores

En este caso, los metodos de Ridge y Lasso, tienen precision global de 0.9386767 y 0.9472835, respectivamente, su precision por categoria es bastante buena es decir todos los valores en el caso de Lasso estan sobre 0,90 y en el caso de Ridge encima de 0,88. El caso de la logistica es opuesto, la estimacion no resulta buena con una precision de 0.2275417.Cabe indicar que en tareas pasadas han habido mejores resultados, una precision global en el caso de arboles aleatorios de 0.9601937 y el de XGBoosting de 0.958042, aunque el SVM radial tiene tambien precision global alta no distingue tan bien por categoria como estos metodos anteriores. Por ello resulta mejor tanto el bosques aleatorio como el XGboosting, al tener todos los numeros con precision por encima de 0,90. Con una precision global de 0.964497 el SVM radial es el que mejor estima la variabilidad del modelo. El SVM ademas de tener una precision global alta, tambien tiene una precision por categoria bastante elevada en todos los numeros aunque no tan optima como estos dos metodos anteriores, a diferencia de los otros metodos. Es decir kvecinos tambien tuvo una precision global alta pero no es preciso con todos los numeros por igual. Debe senalarse que de los modelos anteriores el de arboles de decision tambien tiene mal desempeno, igual que bayes. A pesar de ello, puede senalarse la red neuronal tanto nnet como neuralnet tardan mucho en procesar los datos, mucho mas que en el caso de los kvecinos, por lo que, para el uso de equipo con baja capacidad de procesamiento puede resultar mas optimo SVM o incluso kvencinos. En el caso de los kvecinos se obtuvo precision global de 0.9585799, aun con kvecinos es superior que con la aproximacion de redes nnet (0.8682087).

