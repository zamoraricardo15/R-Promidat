---
title: "Tarea7_Ricardo Zamora Mennigke_Mineria de Datos I"
author: "Ricardo Zamora Mennigke"
date: "5/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```

#Tarea 07
#Mineria de Datos I
#Ricardo Zamora Mennigke


```{r cars}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(glue)
library(scales)
library(xgboost)
library(randomForest)
```


Pregunta 1: [25 puntos] En este ejercicio usaremos los datos (voces.csv). Se trata de un problema de reconocimiento de g´enero mediante el an´alisis de la voz y el habla. Esta base de datos fue creada para identificar una voz como masculina o femenina, bas´andose en las propiedades ac´usticas de la voz y el habla. El conjunto de datos consta de 3.168 muestras de voz grabadas, recogidas de hablantes masculinos y femeninos. Las muestras de voz se preprocesan mediante an´alisis ac´ustico en R, utilizando los paquetes de ondas marinas y de sinton´ıa de R, con un rango de frecuencia analizada de 0hz-280hz (rango vocal humano). El conjunto de datos tiene las siguientes propiedades ac´usticas (variables) de cada voz:


1. Cargue la tabla de datos voces.csv en R. No olvide recodificar la variable a predecircomo categ´orica

```{r pruiwuifrgeghfjhdessureg, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase3")
datos<-read.csv("voces.csv",dec='.',header=T)
str(datos)
datos$genero <- factor(datos$genero,ordered = TRUE) ##ya es un factor es una linea repetitiva pero que ordena 
```

```{r pruiwuifrjdhfjhdessureg, echo=TRUE}
barplot(prop.table(table(datos$genero)),col=c("orange","blue","green"),main="Distribución de la variable por predecir")
```
El problema esta equilibrado.


2. Usando el comando sample de R genere al azar una tabla aprendizaje con un 80 % de los datos y con el resto de los datos genere una tabla de aprendizaje.

```{r pueyfifihhhhhjfjec, echo=TRUE}
muestra <- sample(1:nrow(datos),floor(nrow(datos)*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
nrow(ttesting)
nrow(taprendizaje)
```

3. Con el paquete traineR genere Modelos Predictivos usando Bosques Aleatorios con 200 ´arboles, el M´etodo de Potenciaci´on con iter = 200 y XGBoosting con nrounds = 200, luego para este modelo calcule la matriz de confusi´on, la precisi´on, la precisi´on positiva, la precisi´on negativa, los falsos positivos, los falsos negativos, la acertividad positiva y la acertividad negativa.

```{r pueyfifijfjheifhreec, echo=TRUE}
indices.general <- function(MC) {
  precision.global <- sum(diag(MC))/sum(MC)
  error.global <- 1 - precision.global
  precision.categoria <- diag(MC)/rowSums(MC)
  precision.positiva <- MC[2, 2]/(MC[2, 2] + MC[2, 1])
  precision.negativa <- MC[1, 1]/(MC[1, 1] + MC[1, 2])
  falsos.positivos <- 1 - precision.negativa
  falsos.negativos <- 1 - precision.positiva
  asertividad.positiva <- MC[2, 2]/(MC[1, 2] + MC[2, 2])
  asertividad.negativa <- MC[1, 1]/(MC[1, 1] + MC[2, 1])
  res <- list(matriz.confusion = MC, precision.global = precision.global, error.global = error.global, 
              precision.categoria = precision.categoria, precision.positiva = precision.positiva, precision.negativa=precision.negativa, 
              falsos.positivos=falsos.positivos, falsos.negativos=falsos.negativos, asertividad.positiva=asertividad.positiva,
              asertividad.negativa=asertividad.negativa)
  names(res) <- c("Matriz de Confusión", "Precisión Global", "Error Global", "Precisión por categoría", "Precision Positiva", "Precision Negativa",
                  "Falsos Positivos", "Falsos Negativos", "Asertividad Positiva", "Asertividad Negativa")
  return(res)
}

```


Arbol (traineR) con restriccion de 200
```{r pueyffjresghruec, echo=TRUE}
library(traineR)

modelo <- train.randomForest(formula = genero~., data = taprendizaje, importance = T, ntree=200)
modelo
```

```{r pueyffjughrhsuhhjrec, echo=TRUE}
varImpPlot(modelo)
```

```{r pueyffjaffaefughrhsurec, echo=TRUE}
prediccion<-predict(modelo, ttesting, type = "class")

MC<-confusion.matrix(ttesting, prediccion)

indices.general(MC)
```


Potenciacion (traineR) con iter de 200
```{r pueysghrughrhsurec, echo=TRUE}
library(traineR)

modelo <- train.ada(formula = genero~.,data = taprendizaje, iter=200)
prediccion <- predict(modelo, ttesting, type = "class")
plot(modelo,TRUE,TRUE)
```


```{r pueyffjughrhsusvddghrtjtyrec, echo=TRUE}
MC<-confusion.matrix(ttesting, prediccion)

indices.general(MC)
```


XGBoosting (traineR) con nrounds de 200
```{r pyffjresghrughrhsurec, echo=TRUE}
library(traineR)

modelo <- train.xgboost(formula = genero~., data = taprendizaje, nrounds = 200,verbose = F)
prediccion <- predict(modelo, ttesting , type = "class")
```


```{r pueyffjughukfyukfyukrhsurec, echo=TRUE}
MC<-confusion.matrix(ttesting, prediccion)

indices.general(MC)
```

```{r pueyffjesyresughrhsurec, echo=TRUE}
variables.importantes <- xgb.importance(feature_names = colnames(taprendizaje), model = modelo)
xgb.plot.importance(importance_matrix = variables.importantes)
```

4. Construya una tabla para los ´ındices anteriores que permita comparar el resultado de los m´etodos Bosques Aleatorios, el M´etodo de Potenciaci´on y XGBoosting con respecto a los m´etodos de las tareas anteriores ¿Cu´al m´etodo es mejor?

```{r pressurek, echo=TRUE}
x <- data.frame("Modelo" = c("Bosques aleatorios","Potenciacion","XGBoosting","Modelo Bayes","LDA","QDA", "Modelo k-vecinos Todas las variables", "Modelo k-vecinos Seis variables", "Red 15 nodos", "trainR neuralnet 4 nodos", "Arbol de Decision", "TrainR SVM Radial"), "Precision Global" = c(0.9763033,0.9731438, 0.9794629,0.878357, 0.9636651, NA,0.9731438, 0.9810427, 0.9763, 0.9810427, 0.9462875, 0.985782), "Error Global" = c(0.02369668,0.02685624,0.02053712, 0.121643, 0.03633491, NA, 0.02685624, 0.01895735, 0.0237, 0.01895735, 0.05371248, 0.01421801))
x
```

El metodo trainRSVM "Radial" continua siendo el mas preciso y con menor error global. A pesar de ello bosques aleatorios (0.9763033), potenciaciacion (0.9731438) y xgboosting (0.9794629) se muestran como metodos significativamente precisos. De hecho, la diferencia respecto al SVM mencionado no resulta significativa. El metodo de Bayes posee el peor desempeno segun la precision global y el error, analizando la matriz de confusion ademas, se denota que este metodo tiene un exceso importante de datos confundidos. El mejor SVM para este ejercicio es con el default kernel, el radial. Posee una precision bastante alta de 0.9873618. Para este ejercicio parece ser el metodo el que mejor se ha ajustado. El arbol de decisio con una precision global de 0.9462875, estuvo mas bajo. Ademas otras estimaciones tardan mas, es decir,  redes tarda mas entre mas cantidad de nodos, pero la precision global y el error global en los tres casos de redes se mantienen entre 97 y 98%, y 2% y 3%, respectivamente. De los seis modelos (svm, arbol, 3 redes, kvecinos) tomando precision global como criterio principal y revisando un poco la precision de categorias, SVM radial en este caso tiene la precision mas alta , pero se denota que no existe diferencia significativa, ya que siguiendo la finalidad de este ejercicio se realizan distintas simulaciones para comparar. En la mayoria de los casos la precision de la red neuronal especialmente la de 4 nodos se acerca a la que mejor estimacion de svm radial, pero todas las estimaciones usando k vecinos y redes neuronales con distinta cantidad de nodos, han dado precisiones de entre 96,68% y 98,26% como ocurrio en el de 4 nodos contra 15 nodos, es decir, no se notan diferencias significativas. Los svm con otros kernels tambien han sido bastante acertados, de hecho, puede ser la muestra la que influya en la decision.



Pregunta 2: [25 puntos] En esta pregunta utiliza los datos (tumores.csv). Se trata de un conjunto de datos de caracter´ısticas del tumor cerebral que incluye cinco variables de primer orden y ocho de textura y cuatro par´ametros de evaluaci´on de la calidad con el nivel objetivo. La variables son: Media, Varianza, Desviaci´on est´andar, Asimetr´ıa, Kurtosis, Contraste, Energ´ıa, ASM (segundo momento angular), Entrop´ıa, Homogeneidad, Disimilitud, Correlaci´on, Grosor,
PSNR (Pico de la relaci´on se˜nal-ruido), SSIM (´Indice de Similitud Estructurada), MSE (Mean Square Error), DC (Coeficiente de Dados) y la variable a predecir tipo (1 = Tumor, 0 = No-Tumor).
Realice lo siguiente:

1. Cargue la tabla de datos tumores.csv en R y genere en R usando la funci´on createDataPartition(...) del paquete caret la tabla de testing con una 25 % de los datos y con el resto de los datos genere una tabla de aprendizaje.

```{r pruryjfhjel, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase2")
data1<-read.csv("tumores.csv",dec='.',header=T)
head(data1)
```

```{r presuweyruueyf8ryeioremaa, echo=TRUE}
library(caret)
data1$tipo <- factor(data1$tipo,ordered = TRUE)
data1$imagen <- as.integer(data1$imagen,ordered = TRUE)
```

```{r preseuywruuremaa, echo=TRUE}
str(data1)
```

```{r pruiwuifrgegerhdessureg, echo=TRUE}
barplot(prop.table(table(data1$tipo)),col=c("orange","blue","green"),main="Distribución de la variable por predecir")
```
Ejercicio desbalanceado

```{r pressuueyremaa, echo=TRUE}
intrain <- createDataPartition(
  y = data1$tipo,
  p = .75,
  list = FALSE
)
str(intrain)
```

```{r prywteburemaa, echo=TRUE}
taprendizaje <- data1[ intrain,]
ttesting  <- data1[-intrain,]

nrow(taprendizaje)
nrow(ttesting)
```


2. Con el paquete traineR, usando Bosques Aleatorios con 500 ´arboles, el M´etodo de Potenciaci´on con iter = 500 y XGBoosting con nrounds = 500 genere un modelos predictivos para la tabla de aprendizaje.

Arbol (traineR) con restriccion de 500
```{r pueyffjrrughrhsurec, echo=TRUE}
library(traineR)

modelo <- train.randomForest(formula = tipo~., data = taprendizaje, importance = T, ntree=500)
modelo
```

```{r puereasewtrtyyffjughrhsurec, echo=TRUE}
varImpPlot(modelo)
```

```{r pueyffjughrhsujfhioyhfioarec, echo=TRUE}
prediccion<-predict(modelo, ttesting, type = "class")

MC1<-confusion.matrix(ttesting, prediccion)

indices.general(MC1)
```


Potenciacion (traineR) con iter de 500
```{r pueyffjresghrhsurec, echo=TRUE}
library(traineR)

modelo <- train.ada(formula = tipo~.,data = taprendizaje, iter=500)
prediccion <- predict(modelo, ttesting, type = "class")
plot(modelo,TRUE,TRUE)
```


```{r pueyffjughrhsuhwafuiayfiurec, echo=TRUE}
MC2<-confusion.matrix(ttesting, prediccion)

indices.general(MC2)
```


XGBoosting (traineR) con nrounds de 500
```{r pueyffjresghrrec, echo=TRUE}
library(traineR)

modelo <- train.xgboost(formula = tipo~., data = taprendizaje, nrounds = 500, verbose = F)
prediccion <- predict(modelo, ttesting , type = "class")
```


```{r pueyffjuieyiwughrhsurec, echo=TRUE}
MC3<-confusion.matrix(ttesting, prediccion)

indices.general(MC3)
```

```{r pueyffjughrhsurrgioaehgiauehgec, echo=TRUE}
variables.importantes <- xgb.importance(feature_names = colnames(taprendizaje), model = modelo)
xgb.plot.importance(importance_matrix = variables.importantes)
```

3. Usando la funci´on indices.general(...) vista en clase para la tabla de testing calcule la matriz de confusi´on, la precisi´on global, el error global y la precisi´on en cada unos de las 8 fotos. Construya una tabla para los ´ındices anteriores que permita comparar los resultados de Bosques Aleatorios, M´etodo de Potenciaci´on y XGBoosting con respecto a los m´etodos generados en las tareas anteriores ¿Cu´al m´etodo es mejor?

```{r pueyffjaeuguieghiaugughrhsurec, echo=TRUE}
indices.general(MC1) ##Bosques
```

```{r pueyffueiawfiuawgfuifjughrhsurec, echo=TRUE}
indices.general(MC2)  ###Potenciacion
```

```{r pueyffjugagergyioeuygiuayghrhsurec, echo=TRUE}
indices.general(MC3)  ##XGBoosting
```

```{r preujgefek, echo=TRUE}
x <- data.frame("Modelo" = c("Bosques aleatorios","Potenciacion","XGBoosting","Bayes","Modelo k-vecinos", "Modelo kvecinos.traineR", "Modelo Red 2 nodos", "Modelo Arbol Decision", "SVM radial", "SVM Linear", "SVM Sigmoid", "SVM polynomial"), "Precision Global" = c(0.9842767, 0.9811321, 0.0754717, 0.8836478, 0.9559748, 0.9402516, 0.9497, 0.9717, 0.9245283, 0.9748428, 0.9245283, 0.9245283), "Error Global" = c(0.01572327,0.01886792,0.9245283, 0.1163522, 0.04402516, 0.05974843, 0.0503, 0.0283, 0.0754717, 0.02515723, 0.0754717,0.0754717))
x
```

Para el caso de tumores la mejor prediccion parece ser con el metodo de bosques aleatorios con una precision global de 0.9842767, seguido de potenciacion con 0.9811321. Cabe resaltar que XGBoosting no logra distinguir bien la variacion en el problema y tiene la peor precision. Cabe destacar tambien que la precision por categoria es alta cuando existe tumor pero de menos de 0,90 cuando no hay tumor. Esto realmente siguiendo los resultados de tareas anteriores que falta datos de no tumores. El segundo peor metodo es el de BayesNinguno estimado, ademas LDA y QDA no estaban logrando ser estimados. Cabe resaltar que por tratarse de tumores los metodos en general no estan logrando estimar correctamente los casos de no tumor.Todos los kernels dan la misma matrix de confusion en el caso de SVM, excepto el linear que permite identificar ambos casos y tiene la precision global mas alta con 0.9716981, pero una asertividad negativa aun baja de 0.7777778.Comparando de forma sencillo los modelos mas acertados en las tareas anteriores, ya que se han dado varios intentos con resultados de toda clase. El SVM linear parece ser en este ejercicio el que mejor esta asimilando los datos para explicar la variabilidad del caso. Tiene una precision global bastante alta. De hecho, todos los casos probables de no tumor los identifica. Aun asi debe indicarse que se trata con tumores, lo implica que se necesita replantear el modelo, dado que se trata de tumores, lo que es mas importante, es probable que se requier un tamano de muestra mas grande para arrojar datos veridicos ya que en este caso los modelos no estan leyendo completamente bien los casos. En el caso de todos los modelos la precision por categoria ha sido especialmente debil al no detectar los no tumores, esto se explica probablemente por la falta de muestra en estos casos. 


Pregunta 3: [25 puntos] En este ejercicio vamos a predecir n´umeros escritos a mano (Hand Written Digit Recognition), la tabla de de datos est´a en el archivo ZipData 2020.csv. En la figura siguiente se ilustran los datos:

1. Cargue la tabla de datos ZipData 2020.csv en R

```{r pressrywerfefiyriouioqfhklfjureo, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase3")
data2<-read.csv("ZipData_2020.csv",sep=";",dec='.',header=T)
head(data2)
```

```{r preseewuifefferqfwuiyfhoruioweusureo, echo=TRUE}
str(data2)
```

```{r pruiwuifrfreqgegerghjhsjdhfjhdessureg, echo=TRUE}
barplot(prop.table(table(data2$Numero)), main="Distribución de la variable por predecir")
```

2. Con el paquete traineR, usando Bosques Aleatorios, ADABoosting y XGBoosting genere un modelos predictivos y los par´ametros que usted considere m´as conveniente para generar un modelo predictivo para la tabla ZipData 2020.csv usando el 80 % de los datos para la tabla aprendizaje y un 20 % para la tabla testing, luego calcule para los datos de testing la matriz de confusi´on, la precisi´on global y la precisi´on para cada una de las categor´ıas. ¿Son buenos los resultados? Explique.

```{r pueyffjressfrwehKFHWJKFHurec, echo=TRUE}
muestra <- sample(1:nrow(data2),floor(nrow(data2)*0.20))
ttesting <- data2[muestra,]
taprendizaje <- data2[-muestra,]
```


Arbol (traineR) con restriccion de 500
```{r pueyffjresghruurec, echo=TRUE}
library(traineR)

modelo <- train.randomForest(formula = Numero~., data = taprendizaje, importance = T, ntree=500)
modelo
```

```{r pueyffjughageruiyguiyguiagrhsurec, echo=TRUE}
varImpPlot(modelo)
```

```{r pueyffjuaguiegueguhfghrhsurec, echo=TRUE}
prediccion<-predict(modelo, ttesting, type = "class")

MC<-confusion.matrix(ttesting, prediccion)

indices.general(MC)
```



XGBoosting (traineR) con nrounds de 500
```{r pueyffjrughrhsurec, echo=TRUE}
library(traineR)

modelo <- train.xgboost(formula = Numero~., data = taprendizaje, nrounds = 500, verbose = F)
prediccion <- predict(modelo, ttesting , type = "class")
```


```{r pueyffjuargueghuiahgiughrhsurec, echo=TRUE}
MC<-confusion.matrix(ttesting, prediccion)

indices.general(MC)
```

```{r pueyffjaergahjkaehgjkahgughrhsurec, echo=TRUE}
variables.importantes <- xgb.importance(feature_names = colnames(taprendizaje), model = modelo)
xgb.plot.importance(importance_matrix = variables.importantes)
```


3. Compare los resultados con los obtenidos en las tareas anteriores.

Los resultados son buenos. Cabe indicar que ambos modelos tienen una precision global en el caso de arboles aleatorios de 0.9601937 y el de XGBoosting de 0.958042, aunque el SVM radial tiene mayor precision global no distingue tan bien por categoria como estos metodos anteriores. Por ello resulta mejor tanto el bosques aleatorio como el XGboosting, al tener todos los numeros con precision por encima de 0,90. Con una precision global de 0.964497 el SVM radial es el que mejor estima la variabilidad del modelo. El SVM ademas de tener una precision global alta, tambien tiene una precision por categoria bastante elevada en todos los numeros aunque no tan optima como estos dos metodos anteriores, a diferencia de los otros metodos. Es decir kvecinos tambien tuvo una precision global alta pero no es preciso con todos los numeros por igual. Debe senalarse que de los modelos anteriores el de arboles de decision tambien tiene mal desempeno, igual que bayes. A pesar de ello, puede senalarse la red neuronal tanto nnet como neuralnet tardan mucho en procesar los datos, mucho mas que en el caso de los kvecinos, por lo que, para el uso de equipo con baja capacidad de procesamiento puede resultar mas optimo SVM o incluso kvencinos. En el caso de los kvecinos se obtuvo precision global de 0.9585799, aun con kvecinos es superior que con la aproximacion de redes nnet (0.8682087).


Pregunta 4: [25 puntos] La idea de este ejercicio es programar un M´etodo de Consenso Propio basado en los m´etodos K-vecinos m´as cercanos, Redes Neuronales, Arboles de Decisi´on, M´aquinas de Soporte Vectorial (mejor kernel), Bayes, LDA y M´etodos de Potenciaci´on (XGBoosting), con el paquete traineR (excepto para LDA), para esto realice los siguiente:

1. Programe una funci´on Consenso(TAprendizaje,...) que recibe la tabla de entrenamiento y genera 7 muestras aleatorias con reemplazo (Boostraps) de los datos de aprendizaje y luego aplica en cada una de estas muestras uno de los m´etodos predictivos mencionados arriba. Esta funci´on debe retornar un nuevo modelo predictivo que es una lista con dos listas, una con los 7 modelos generados (todos los m´etodos usar´an todas las variables) y otra
lista con las 7 de precisiones globales, respectivamente de cada modelo1 , que denotamos
por (P G1, P G2, . . . , P G7), donde 0 ≤ P Gj ≤ 1 para j = 1, 2, . . . , 7.

```{r pueyffjughrhsfhwiofyuwoiurec, echo=TRUE}
library(caret)
library(randomForest)
library(ada)
library(xgboost)
library(kableExtra)
library(car)
library(e1071)
library (modeest)
library(kknn)
library(nnet)
library(class)
library(MASS)
library(traineR)
```

```{r pueyffjfhwiofyuwoiu, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase3")
datos<-read.csv("voces.csv",dec='.',header=T)
datos <- na.omit(datos)

# muestra <- sample(1:nrow(datos),nrow(datos)*80/100,replace = FALSE)
# aprendizaje <- datos[muestra,]
# testing <- datos[-muestra,]
# nrow(datos)
# nrow(datos)*80/100 ##necesita volverse entero en el paso 3

muestra <- sample(1:nrow(datos),floor(nrow(datos)*0.20))
testing <- datos[muestra,]
aprendizaje <- datos[-muestra,]
nrow(testing)
nrow(aprendizaje)
```

```{r pueyffjughrhsfhwiofyuwoiu, echo=TRUE}
consenso <- function(aprendizaje){
  conteo <- dim(aprendizaje)[1]
  #se generan muestras aleatorias
  m1 <- sample(1:conteo, replace=TRUE)
  ap1 <- aprendizaje[m1,] 
  m2 <- sample(1:conteo, replace=TRUE)
  ap2 <- aprendizaje[m2,]
  m3 <- sample(1:conteo, replace=TRUE)
  ap3 <- aprendizaje[m3,]
  m4 <- sample(1:conteo, replace=TRUE)
  ap4 <- aprendizaje[m4,]
  m5 <- sample(1:conteo, replace=TRUE)
  ap5 <- aprendizaje[m5,]
  m6 <- sample(1:conteo, replace=TRUE)
  ap6 <- aprendizaje[m6,]
  m7 <- sample(1:conteo, replace=TRUE)
  ap7 <- aprendizaje[m7,]
  #Modelos segun metodo
  mod.knn<-train.kknn(genero~., data = ap1 , kmax=200)    
  mod.redes<-train.nnet(genero~ ., data = ap2, size = 4, rang= 0.1, decay = 5e-04,maxit = 600, trace = FALSE, MaxNWts=2000)            
  mod.arboles<-train.rpart(genero ~ ., data = ap3)            
  mod.svm<-train.svm(genero~ ., data = ap4, kernel="radial")   
  mod.bayes <- naiveBayes(genero~.,data=ap5)                
  mod.lda<- lda(genero~., data=ap6)                        
  mod.xgboost<- train.xgboost(formula = genero~., data = ap7, nrounds = 200,verbose = F)
  ##Se genera el consenso
  mod.consenso <- list(kvecinos=mod.knn,red.neuronal=mod.redes,arbol.decision=mod.arboles,SVM=mod.svm,bayes=mod.bayes,LDA=mod.lda,boosting=mod.xgboost)
  return(list(kvecinos=mod.knn,red.neuronal=mod.redes,arbol.decision=mod.arboles,SVM=mod.svm,bayes=mod.bayes,LDA=mod.lda,boosting=mod.xgboost))
}

mod.consenso <- consenso(aprendizaje)
```


2. Programe una funci´on Predice(TTesting,Modelo,...) que recibe la tabla de testing y el modelo generado en 1. Luego, para predecir aplica en cada una de las filas de la tabla de testing los 7 modelos predictivos que vienen en Modelo y se establece un consenso de todos los resultados. Se debe programar una f´ormula en R que le d´e mayor importancia a los m´etodos con mejor precisi´on global.

```{r pjughrhsfuwoiurec, echo=TRUE}
predice<-function(testing,mod.consenso){
  ##Se generan las predicciones
  p.knn<-((predict(mod.consenso$kvecinos, testing)))
  p.red<-((predict(mod.consenso$red.neuronal, testing, type = "class")))
  p.arbol<-((predict(mod.consenso$arbol.decision, testing, type = "class")))
  p.svm1<-((predict(mod.consenso$SVM, testing, type = "class")))
  p.bayes <-((predict(mod.consenso$bayes,testing)))
  p.lda<-((predict(mod.consenso$LDA,testing, type = "class")))
  p.xgboost<- ((predict(mod.consenso$boosting, testing, type = "class")))
  metodos<-data.frame(p.knn,p.red,p.arbol,p.svm1,p.bayes,p.lda, p.xgboost)
  # metodos$p.knn<-metodos$p.knn[1]
  # metodos$p.red<-metodos$p.red[1]
  # metodos$p.arbol<-metodos$p.arbol[1]
  # metodos$p.svm1<-metodos$p.svm1[1]
  # metodos$p.bayes<-metodos$p.bayes[1]
  # metodos$p.lda<-metodos$p.lda[1]
  # metodos$p.xgboost<-metodos$p.xgboost[1]
#Se estandarizan numericamente las estimaciones
  # get_numbers <- function(X) {
  #   X[toupper(X) != tolower(X)] <- NA
  #   return(as.double(as.character(X)))
  # }
#
  maximos <-  rep(0,dim(metodos)[1])
  for (i in 1:dim(metodos)[1]){
    maximos[i]<-max(as.numeric(testing[i,]))
    }
 confusion<-table(testing$genero,maximos)
 return(confusion)

}
predice(testing,mod.consenso)
```

3. Usando la tabla de datos voces.csv genere al azar una tabla de testing con un 20 % de los datos y con el resto de los datos construya una tabla de aprendizaje.

```{r pruiwuifrgegerdhfjhsureg, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase3")
datos<-read.csv("voces.csv",dec='.',header=T)
str(datos)
datos$genero <- factor(datos$genero,ordered = TRUE) ##ya es un factor es una linea repetitiva pero que ordena 
```


```{r pueyfiergteyfijfjec, echo=TRUE}
muestra <- sample(1:nrow(datos),floor(nrow(datos)*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
nrow(ttesting)
nrow(taprendizaje)
```

4. Genere modelos predictivos usando la funci´on Consenso y la funci´on randomForest (con solamente 7 ´arboles, es decir, 7 boostraps), luego para la tabla de testing calcule, con ambos m´etodos, calcule la precisi´on global, el error global y la precisi´on por clases. ¿Cu´al m´etodo es mejor?

```{r pueygyegfcegfifijfjreec, echo=TRUE}
indices.general <- function(MC) {
  precision.global <- sum(diag(MC))/sum(MC)
  error.global <- 1 - precision.global
  precision.categoria <- diag(MC)/rowSums(MC)
  precision.positiva <- MC[2, 2]/(MC[2, 2] + MC[2, 1])
  precision.negativa <- MC[1, 1]/(MC[1, 1] + MC[1, 2])
  falsos.positivos <- 1 - precision.negativa
  falsos.negativos <- 1 - precision.positiva
  asertividad.positiva <- MC[2, 2]/(MC[1, 2] + MC[2, 2])
  asertividad.negativa <- MC[1, 1]/(MC[1, 1] + MC[2, 1])
  res <- list(matriz.confusion = MC, precision.global = precision.global, error.global = error.global, 
              precision.categoria = precision.categoria, precision.positiva = precision.positiva, precision.negativa=precision.negativa, 
              falsos.positivos=falsos.positivos, falsos.negativos=falsos.negativos, asertividad.positiva=asertividad.positiva,
              asertividad.negativa=asertividad.negativa)
  names(res) <- c("Matriz de Confusión", "Precisión Global", "Error Global", "Precisión por categoría", "Precision Positiva", "Precision Negativa",
                  "Falsos Positivos", "Falsos Negativos", "Asertividad Positiva", "Asertividad Negativa")
  return(res)
}

```


```{r pueyfsrgrsgrdgifijfjreec, echo=TRUE}

mod.random.forest<-randomForest(genero~.,data=aprendizaje,ntree=7)
pred.random.forest<-predict(mod.random.forest, testing)
MC.random.forest<-table(testing$genero,pred.random.forest)
rf <- indices.general(MC.random.forest)

mod.consenso <- consenso(aprendizaje)

```


```{r pueyfific, echo=TRUE}
pred.consenso<-predice(testing,mod.consenso)
indices.general(pred.consenso)
```


```{r pueyfifretaeryafiec, echo=TRUE}
indices.general(MC.random.forest)
```

En este caso, el modelo de consenso generado presenta problemas para estimar e identificar las categorias variables del problema. La programacion muestra un error global bastante amplio. En este caso se muestra una precision gloabal de 0.9826224 para el randomForest este muestra una gran capacidad de prediccion de los voces. Con una precision por categoria de 0.9876543 en femenino y 0.9773463 en masculino existe buena prediccion.















































