---
title: "Tarea 6_Ricardo Zamora Mennigke_Mineria de Datos I"
author: "Ricardo Zamora Mennigke"
date: "5/6/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```


#Tarea 06
#Mineria de Datos I
#Ricardo Zamora Mennigke

```{r cars}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(glue)
library(scales)
```


Pregunta 1: [10 puntos] Supongamos que se tiene una nueva fila o registro 12 = (1, 3, 2, 4, ?) en la base de datos de la filmina 18 en la presentaci´on del m´etodo Bayes, prediga (a mano) si el individuo corresponde a un buen pagador o a un mal pagador.

##Revisar documento adjunto


Pregunta 2: [10 puntos] Supongamos que se tiene una nueva fila o registro t = (Pedro, M, 4, ?) en la base de datos de la filmina 23 en la presentaci´on del m´etodo Bayes, prediga (a mano) si Pedro corresponde a la clase peque˜no, mediano o alto.

##Revisar documento adjunto

Pregunta 3: [20 puntos] En este ejercicio usaremos los datos (voces.csv). Se trata de un problema de reconocimiento de g´enero mediante el an´alisis de la voz y el habla. Esta base de datos fue creada para identificar una voz como masculina o femenina, bas´andose en las propiedades ac´usticas de la voz y el habla. El conjunto de datos consta de 3.168 muestras de voz grabadas, recogidas de hablantes masculinos y femeninos. Las muestras de voz se preprocesan
mediante an´alisis ac´ustico en R, utilizando los paquetes de ondas marinas y de sinton´ıa de R, con un rango de frecuencia analizada de 0hz-280hz (rango vocal humano). El conjunto de datos tiene las siguientes propiedades ac´usticas (variables) de cada voz:

Realice lo siguiente:
1. Cargue la tabla de datos voces.csv en R. No olvide recodificar la variable a predecir como categ´orica.

```{r pruiwuifrgegerdhfjhdessureg, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase3")
datos<-read.csv("voces.csv",dec='.',header=T)
str(datos)
datos$genero <- factor(datos$genero,ordered = TRUE) ##ya es un factor es una linea repetitiva pero que ordena 
```

```{r pruiwuifrjdhfjhdessureg, echo=TRUE}
barplot(prop.table(table(datos$genero)),col=c("orange","blue","green"),main="Distribución de la variable por predecir")
```
El problema esta equilibrado.

2. Usando el comando sample de R genere al azar una tabla aprendizaje con un 80 % de los datos y con el resto de los datos genere una tabla de aprendizaje.

```{r pueyfifijfjec, echo=TRUE}
muestra <- sample(1:nrow(datos),floor(nrow(datos)*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
```


3. Genere un Modelo Predictivo usando Na¨ıve Bayes, con el paquete traineR, luego para este modelo calcule la matriz de confusi´on, la precisi´on, la precisi´on positiva, la precisi´on negativa, los falsos positivos, los falsos negativos, la acertividad positiva y la acertividad negativa.

```{r pueyfifijfjreec, echo=TRUE}
indices.general <- function(MC) {
  precision.global <- sum(diag(MC))/sum(MC)
  error.global <- 1 - precision.global
  precision.categoria <- diag(MC)/rowSums(MC)
  precision.positiva <- MC[2, 2]/(MC[2, 2] + MC[2, 1])
  precision.negativa <- MC[1, 1]/(MC[1, 1] + MC[1, 2])
  falsos.positivos <- 1 - precision.negativa
  falsos.negativos <- 1 - precision.positiva
  asertividad.positiva <- MC[2, 2]/(MC[1, 2] + MC[2, 2])
  asertividad.negativa <- MC[1, 1]/(MC[1, 1] + MC[2, 1])
  res <- list(matriz.confusion = MC, precision.global = precision.global, error.global = error.global, 
              precision.categoria = precision.categoria, precision.positiva = precision.positiva, precision.negativa=precision.negativa, 
              falsos.positivos=falsos.positivos, falsos.negativos=falsos.negativos, asertividad.positiva=asertividad.positiva,
              asertividad.negativa=asertividad.negativa)
  names(res) <- c("Matriz de Confusión", "Precisión Global", "Error Global", "Precisión por categoría", "Precision Positiva", "Precision Negativa",
                  "Falsos Positivos", "Falsos Negativos", "Asertividad Positiva", "Asertividad Negativa")
  return(res)
}

```

```{r pueyffjresghrughrhsurec, echo=TRUE}
library(e1071)

modelo <- naiveBayes(genero ~ .,data = taprendizaje)
prediccion <- predict(modelo, ttesting[,-21])
MC <- table(ttesting[,21], prediccion)
indices.general(MC)
```

4. Genere Modelos Predictivos usando LDA y QDA, con el paquete MASS, luego para este modelo calcule la matriz de confusi´on, la precisi´on, la precisi´on positiva, la precisi´on negativa, los falsos positivos, los falsos negativos, la acertividad positiva y la acertividad negativa, puede ser que QDA falle.

LDA
```{r pueyffjfssewfressurec, echo=TRUE}
library(MASS)
library(class)
```

```{r pueyffjrregrgesarggesgsurec, echo=TRUE}
modelo <- lda(genero~., data=taprendizaje)
modelo
```

```{r pueyffjruwryuweyruwyressurec, echo=TRUE}
prediccion <- predict(modelo,ttesting)
head(prediccion$class)
```

```{r pueyfewhfiweyhiowffjressurec, echo=TRUE}
MC<-table(ttesting[,21],prediccion$class)
indices.general(MC)
```

QDA
```{r pueyuweyuitrfuiweyeuiffjressurec, echo=TRUE}
library(dummies)
library(MASS)
library(class)
library(caret)
```

```{r pueyrtyshyrhfifijfjec, echo=TRUE}
muestra <- sample(1:nrow(datos),floor(nrow(datos)*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
```

```{r pueyffrgasgreagergajressurec, echo=TRUE}
modelo <- qda(genero~., data=taprendizaje)
modelo
```

```{r pueyffjresshrstrhsrhrthtsurec, echo=TRUE}
prediccion <- predict(modelo,ttesting)
head(prediccion$class)
```

```{r pueyffshrsthtshshjressurec, echo=TRUE}
MC<-table(ttesting[,21],prediccion$class)
indices.general(MC)
```

5. Construya una tabla para los ´ındices anteriores que permita comparar el resultado de los m´etodos Bayes, LDA y QDA con respecto a los m´etodos de las tareas anteriores ¿Cu´al m´etodo es mejor?

```{r pressurek, echo=TRUE}
x <- data.frame("Modelo" = c("Modelo Bayes","LDA","QDA", "Modelo k-vecinos Todas las variables", "Modelo k-vecinos Seis variables", "Red 15 nodos", "trainR neuralnet 4 nodos", "Arbol de Decision", "TrainR SVM Radial"), "Precision Global" = c(0.878357, 0.9636651, NA,0.9731438, 0.9810427, 0.9763, 0.9810427, 0.9462875, 0.985782), "Error Global" = c(0.121643, 0.03633491, NA, 0.02685624, 0.01895735, 0.0237, 0.01895735, 0.05371248, 0.01421801))
x


```

El metodo de Bayes posee el peor desempeno segun la precision global y el error, analizando la matriz de confusion ademas, se denota que este metodo tiene un exceso importante de datos confundidos. El mejor SVM para este ejercicio es con el default kernel, el radial. Posee una precision bastante alta de 0.9873618. Para este ejercicio parece ser el metodo el que mejor se ha ajustado. El arbol de decisio con una precision global de 0.9462875, estuvo mas bajo. Ademas otras estimaciones tardan mas, es decir,  redes tarda mas entre mas cantidad de nodos, pero la precision global y el error global en los tres casos de redes se mantienen entre 97 y 98%, y 2% y 3%, respectivamente. De los seis modelos (svm, arbol, 3 redes, kvecinos) tomando precision global como criterio principal y revisando un poco la precision de categorias, SVM radial en este caso tiene la precision mas alta , pero se denota que no existe diferencia significativa, ya que siguiendo la finalidad de este ejercicio se realizan distintas simulaciones para comparar. En la mayoria de los casos la precision de la red neuronal especialmente la de 4 nodos se acerca a la que mejor estimacion de svm radial, pero todas las estimaciones usando k vecinos y redes neuronales con distinta cantidad de nodos, han dado precisiones de entre 96,68% y 98,26% como ocurrio en el de 4 nodos contra 15 nodos, es decir, no se notan diferencias significativas. Los svm con otros kernels tambien han sido bastante acertados, de hecho, puede ser la muestra la que influya en la decision.



Pregunta 4: [20 puntos] Para la presentaci´on del An´alisis Discriminante complete la demostraci´on de la Filmina 6 y la demostraci´on de la Filmina 7.

##Revisar documento adjunto



Pregunta 5: [20 puntos] En esta pregunta utiliza los datos (tumores.csv). Se trata de un conjunto de datos de caracter´ısticas del tumor cerebral que incluye cinco variables de primer orden y ocho de textura y cuatro par´ametros de evaluaci´on de la calidad con el nivel objetivo. La variables son: Media, Varianza, Desviaci´on est´andar, Asimetr´ıa, Kurtosis, Contraste, Energ´ıa, ASM (segundo momento angular), Entrop´ıa, Homogeneidad, Disimilitud, Correlaci´on, Grosor, PSNR (Pico de la relaci´on se˜nal-ruido), SSIM (´Indice de Similitud Estructurada), MSE (Mean Square Error), DC (Coeficiente de Dados) y la variable a predecir tipo (1 = Tumor, 0 =
No-Tumor).
Realice lo siguiente:

1. Cargue la tabla de datos tumores.csv en R y genere en R usando la funci´on createDataPartition(...) del paquete caret la tabla de testing con una 25 % de los datos y con el resto de los datos genere una tabla de aprendizaje.

```{r pruryjfhjel, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase2")
data1<-read.csv("tumores.csv",dec='.',header=T)
head(data1)
```

```{r presuweyruueyf8ryeioremaa, echo=TRUE}
library(caret)
data1$tipo <- factor(data1$tipo,ordered = TRUE)
```

```{r preseuywruuremaa, echo=TRUE}
str(data1)
```

```{r pruiwuifrgegerhdessureg, echo=TRUE}
barplot(prop.table(table(data1$tipo)),col=c("orange","blue","green"),main="Distribución de la variable por predecir")
```
Ejercicio desbalanceado

```{r pressuueyremaa, echo=TRUE}
intrain <- createDataPartition(
  y = data1$tipo,
  p = .75,
  list = FALSE
)
str(intrain)
```

```{r prywteburemaa, echo=TRUE}
taprendizaje <- data1[ intrain,]
ttesting  <- data1[-intrain,]

nrow(taprendizaje)
nrow(ttesting)
```

2. Usando Na¨ıve Bayes, LDA y QDA genere un modelos predictivos para la tabla de aprendizaje, puede ser que LDA y QDA generen errores.

#NaiveBayes
```{r pueyffjhtsrtsrhjyjkressurec, echo=TRUE}
library(e1071)

modelo <- naiveBayes(tipo ~ .,data = taprendizaje)
prediccion <- predict(modelo, ttesting[,-18])
MC <- table(ttesting[,18], prediccion)
indices.general(MC)
```
La estimacion es completa

#LDA
```{r pueyffjressiutkilltuiltlurec, echo=TRUE}
library(e1071)

modelo <- lda(tipo ~ .,data = taprendizaje)
prediccion <- predict(modelo,ttesting)
prediccion$class
MC <- table(ttesting[,18], prediccion)
indices.general(MC)
```
LDA falla

#QDA
```{r pueyffjtltltlitlitressurec, echo=TRUE}
library(e1071)

modelo <- qda(tipo ~ .,data = taprendizaje)
prediccion <- predict(modelo,ttesting)
prediccion$class
MC <- table(ttesting[,18], prediccion)
indices.general(MC)
```
QDA falla

3. Usando la funci´on indices.general(...) vista en clase para la tabla de testing calcule la
matriz de confusi´on, la precisi´on global, el error global y la precisi´on en cada de las clases.
Construya una tabla para los ´ındices anteriores que permita comparar los resultados de
Na¨ıve Bayes, LDA y QDA con respecto a los m´etodos generados en las tareas anteriores
¿Cu´al m´etodo es mejor?

```{r pueyfweirutweuirfjressurec, echo=TRUE}
library(e1071)

modelo <- naiveBayes(tipo ~ .,data = taprendizaje)
prediccion <- predict(modelo, ttesting[,-18])
MC <- table(ttesting[,18], prediccion)
indices.general(MC)
```

```{r preujgefek, echo=TRUE}
x <- data.frame("Modelo" = c("Bayes","Modelo k-vecinos", "Modelo kvecinos.traineR", "Modelo Red 2 nodos", "Modelo Arbol Decision", "SVM radial", "SVM Linear", "SVM Sigmoid", "SVM polynomial"), "Precision Global" = c(0.8836478, 0.9559748, 0.9402516, 0.9497, 0.9717, 0.9245283, 0.9748428, 0.9245283, 0.9245283), "Error Global" = c(0.1163522, 0.04402516, 0.05974843, 0.0503, 0.0283, 0.0754717, 0.02515723, 0.0754717,0.0754717))
x
```

El peor metodo es el de BayesNinguno estimado, ademas LDA y QDA no estan logrando ser estimados. Cabe resaltar que por tratarse de tumores los metodos en general no estan logrando estimar correctamente los casos de no tumor.Todos los kernels dan la misma matrix de confusion en el caso de SVM, excepto el linear que permite identificar ambos casos y tiene la precision global mas alta con 0.9716981, pero una asertividad negativa aun baja de 0.7777778.Comparando de forma sencillo los modelos mas acertados en las tareas anteriores, ya que se han dado varios intentos con resultados de toda clase. El SVM linear parece ser en este ejercicio el que mejor esta asimilando los datos para explicar la variabilidad del caso. Tiene una precision global bastante alta. De hecho, todos los casos probables de no tumor los identifica. Aun asi debe indicarse que se trata con tumores, lo implica que se necesita replantear el modelo, dado que se trata de tumores, lo que es mas importante, es probable que se requier un tamano de muestra mas grande para arrojar datos veridicos ya que en este caso los modelos no estan leyendo completamente bien los casos. En el caso de todos los modelos la precision por categoria ha sido especialmente debil al no detectar los no tumores, esto se explica probablemente por la falta de muestra en estos casos. 


Pregunta 6: [20 puntos] En este ejercicio vamos a predecir n´umeros escritos a mano (Hand Written Digit Recognition), la tabla de de datos est´a en el archivo ZipData 2020.csv. En la figura siguiente se ilustran los datos:

1. Cargue la tabla de datos ZipData 2020.csv en R.

```{r pressrywerfefiyriouioqfhklfjureo, echo=TRUE}
setwd("C:/Users/rzamoram/Documents/Machine Learning/Mineria de Datos I/Clase3")
data2<-read.csv("ZipData_2020.csv",sep=";",dec='.',header=T)
head(data2)
```

```{r preseewuifefferqfwuiyfhoruioweusureo, echo=TRUE}
str(data2)
```

```{r pruiwuifrfreqgegerghjhsjdhfjhdessureg, echo=TRUE}
barplot(prop.table(table(data2$Numero)), main="Distribución de la variable por predecir")
```

2. Usando Na¨ıve Bayes, LDA y QDA genere un modelos predictivos y los par´ametros que usted considere m´as conveniente para generar un modelo predictivo para la tabla ZipData 2020.csv usando el 80 % de los datos para la tabla aprendizaje y un 20 % para la tabla testing, luego calcule para los datos de testing la matriz de confusi´on, la precisi´on global y la precisi´on para cada una de las categor´ıas. ¿Son buenos los resultados? Explique.

```{r pueyffjressfrwehKFHWJKFHurec, echo=TRUE}
library(e1071)

muestra <- sample(1:nrow(data2),floor(nrow(data2)*0.20))
ttesting <- data2[muestra,]
taprendizaje <- data2[-muestra,]
```


```{r pueyffjressujdhfwiwiefuiowefuieforec, echo=TRUE}
modelo <- naiveBayes(Numero ~ .,data = taprendizaje)
prediccion <- predict(modelo, ttesting[,-1])
MC <- table(ttesting[,1], prediccion)
indices.general(MC)
```

##LDA
```{r pueyffjrifyioerujdhfwiorec, echo=TRUE}
modelo <- lda(Numero ~ .,data = taprendizaje)
prediccion <- predict(modelo,ttesting)
head(prediccion$class)
```

```{r pueyffjrdfguiehfwiorec, echo=TRUE}
MC <- table(ttesting[, 1], prediccion$class)
indices.general(MC)
```

##QDA
```{r pueyfewufyiuwyfiuewyffjressujdhfwiorec, echo=TRUE}
modelo <- qda(Numero ~ .,data = taprendizaje)
prediccion <- predict(modelo,ttesting)
head(prediccion$class)
```

```{r pueyffjressujduidfguiehfwioroiurfiouec, echo=TRUE}
MC <- table(ttesting[, 1], prediccion$class)
indices.general(MC)
```
Los resultados no son buenos. El modelo LDA  con una precision global de 0.9123185 genera los mejores resultados ademas por cada uno de los numeros categorias parece arrojar mejores resultados que Bayes que posee una precision global de apenas 0.7654653.


3. Compare los resultados con los obtenidos en las tareas anteriores.

Con una precision global de 0.9123185, el LDA tiene los mejores resultados de Bayes, LDA y QDA. Qda no logro estimar este ejercicio y Bayes tiene una precision global muy baja de 0.7654653. Con una precision global de 0.964497 el SVM radial es el que mejor estima la variabilidad del modelo. El SVM ademas de tener una precision global alta, tambien tiene una precision por categoria bastante elevada en todos los numeros, a diferencia de los otros metodos. Es decir kvecinos tambien tuvo una precision global alta pero no es preciso con todos los numeros por igual. Debe senalarse que de los modelos anteriores el de arboles de decision tambien tiene mal desempeno. A pesar de ello, puede senalarse la red neuronal tanto nnet como neuralnet tardan mucho en procesar los datos, mucho mas que en el caso de los kvecinos, por lo que, para el uso de equipo con baja capacidad de procesamiento puede resultar mas optimo SVM o incluso kvencinos. En el caso de los kvecinos se obtuvo precision global de 0.9585799, aun con kvecinos es superior que con la aproximacion de redes nnet (0.8682087).





